{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SkipGramFoo(torch.nn.Module):\n",
    "  def __init__(self, voc, emb, ctx):\n",
    "    super().__init__()\n",
    "    self.ctx = ctx\n",
    "    self.emb = torch.nn.Embedding(num_embeddings=voc, embedding_dim=emb)\n",
    "    self.ffw = torch.nn.Linear(in_features=emb, out_features=voc, bias=False)\n",
    "    self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "  # def forward(self, inpt, trgs, rand):\n",
    "  #   emb = self.emb(inpt)\n",
    "  #   ctx = self.ffw.weight[trgs]\n",
    "  #   rnd = self.ffw.weight[rand]\n",
    "  #   out = torch.mm(ctx, emb.T)\n",
    "  #   rnd = torch.mm(rnd, emb.T)\n",
    "  #   out = self.sig(out).clamp(min=1e-7, max=1 - 1e-7)\n",
    "  #   rnd = self.sig(rnd).clamp(min=1e-7, max=1 - 1e-7)\n",
    "  #   pst = -out.log().mean()\n",
    "  #   ngt = -(1 - rnd).log().mean()\n",
    "  #   return pst + ngt\n",
    "\n",
    "#new forwarding for batch size \n",
    "  def forward(self, inpt, trgs, rand):\n",
    "    # Embedding lookup for input (shape: [batch_size, embedding_dim])\n",
    "    emb = self.emb(inpt)\n",
    "    \n",
    "    # Ensure context (trgs) and random samples (rand) have the same batch size as inpt\n",
    "    batch_size = inpt.size(0)  # Get the current batch size\n",
    "\n",
    "    # Slice or generate the random tensor according to the input batch size\n",
    "    rand = rand[:batch_size]  # Adjust random tensor to match current batch size\n",
    "    \n",
    "    ctx = self.ffw.weight[trgs.to(inpt.device)]  # Shape: [batch_size, 2, embedding_dim]\n",
    "    rnd = self.ffw.weight[rand.to(inpt.device)]  # Shape: [batch_size, 2, embedding_dim]\n",
    "\n",
    "    # Ensure the batch size matches before performing batch matrix multiplication\n",
    "    assert ctx.size(0) == emb.size(0), f\"Context batch size {ctx.size(0)} doesn't match embeddings batch size {emb.size(0)}\"\n",
    "    assert rnd.size(0) == emb.size(0), f\"Random batch size {rnd.size(0)} doesn't match embeddings batch size {emb.size(0)}\"\n",
    "    \n",
    "    # Perform batch matrix multiplication\n",
    "    out = torch.bmm(ctx, emb.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, 2)\n",
    "    rnd = torch.bmm(rnd, emb.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, 2)\n",
    "    \n",
    "    # Apply sigmoid and clamp to prevent NaNs\n",
    "    out = self.sig(out).clamp(min=1e-7, max=1 - 1e-7)\n",
    "    rnd = self.sig(rnd).clamp(min=1e-7, max=1 - 1e-7)\n",
    "\n",
    "    # Calculate loss\n",
    "    pst = -out.log().mean()   # Positive sample log-likelihood\n",
    "    ngt = -(1 - rnd).log().mean()  # Negative sample log-likelihood\n",
    "    \n",
    "    return pst + ngt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mFoo.emb is None:\n",
    "    raise ValueError(\"Embedding layer is not initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231284, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_titles_df = pd.read_csv('valid_titles_80_scores')\n",
    "valid_titles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omare\\AppData\\Local\\Temp\\ipykernel_23060\\157362959.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mFoo.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the updated vocabulary\n",
    "with open('vocab_dict.pkl', 'rb') as fp:\n",
    "    updated_vocab = pickle.load(fp)\n",
    "\n",
    "# Step 1: Load the dataframe\n",
    "valid_titles_df = pd.read_csv('valid_titles_80_scores')  # Assuming the file is valid_titles.csv\n",
    "titles = valid_titles_df['title_cleaned'].tolist()\n",
    "\n",
    "# Function to create a reverse vocabulary from the updated vocabulary\n",
    "def create_reverse_vocab(vocab):\n",
    "    return {word: index for index, word in vocab.items()}\n",
    "\n",
    "# Load the reverse vocabulary\n",
    "reverse_vocab = create_reverse_vocab(updated_vocab)\n",
    "\n",
    "# Tokenize the titles using the reverse vocabulary\n",
    "def tokenize_titles(titles, reverse_vocab):\n",
    "    tokens = []\n",
    "    \n",
    "    for title in titles:\n",
    "        words = title.lower().split()  # Convert the title to lowercase to match training preprocessing\n",
    "        \n",
    "        tokenized = []\n",
    "        for word in words:\n",
    "            if word in reverse_vocab:\n",
    "                tokenized.append(reverse_vocab[word])  # Get the index from reverse_vocab\n",
    "            # No else clause needed; unknown words are simply skipped\n",
    "        \n",
    "        tokens.append(tokenized)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Now we use the reverse_vocab to tokenize the titles\n",
    "tokenized_titles = tokenize_titles(titles, reverse_vocab)\n",
    "\n",
    "\n",
    "# Step 3: Load the trained SkipGram model\n",
    "model_path = \"skipgram_model_titles.pth\"\n",
    "embedding_dim = 64  # Set to the same dimension used when training\n",
    "\n",
    "# Ensure the model is moved to the GPU\n",
    "mFoo = SkipGramFoo(len(updated_vocab), embedding_dim, 2).to(device)\n",
    "\n",
    "# Load the saved model weights\n",
    "mFoo.load_state_dict(torch.load(model_path))\n",
    "mFoo.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Step 4: Generate embeddings for each title\n",
    "def get_embeddings_for_titles(tokenized_titles, model):\n",
    "    embeddings_list = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations for faster performance\n",
    "        for tokens in tokenized_titles:\n",
    "            if len(tokens) > 0:\n",
    "                # Move the tokens to the GPU\n",
    "                token_tensor = torch.LongTensor(tokens).to(device)\n",
    "                \n",
    "                # Get the embeddings for each token in the title\n",
    "                token_embeddings = model.emb(token_tensor)  # Shape: [num_tokens, embedding_dim]\n",
    "                \n",
    "                # Average the token embeddings to get a single vector for the entire title\n",
    "                title_embedding = token_embeddings.mean(dim=0)  # Shape: [embedding_dim]\n",
    "                \n",
    "                embeddings_list.append(title_embedding.cpu().numpy())  # Store the embedding as a NumPy array\n",
    "            else:\n",
    "                # Handle empty titles (if any)\n",
    "                embeddings_list.append(torch.zeros(embedding_dim).cpu().numpy())  # Zero vector for empty titles\n",
    "    \n",
    "    return embeddings_list\n",
    "\n",
    "# Generate embeddings for all the tokenized titles\n",
    "embeddings = get_embeddings_for_titles(tokenized_titles, mFoo)\n",
    "\n",
    "# Step 5: Store the embeddings\n",
    "# Convert to a DataFrame for easier saving/processing later\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "# Save the embeddings to a file (optional)\n",
    "embeddings_df.to_csv('title_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 419, 107, 342, 10, 2918],\n",
       " [109, 1341, 536, 66, 143, 2806, 1, 1035, 7912],\n",
       " [3494, 300],\n",
       " [328, 12416, 7499, 756, 763, 1341, 4, 4442],\n",
       " [1, 25, 638, 2, 1, 7052],\n",
       " [49, 269, 3, 2909, 648, 101, 2909, 617],\n",
       " [64, 1298, 15319],\n",
       " [359, 136, 438, 173, 1645, 5956, 49, 2904],\n",
       " [12568, 4891, 284, 2076],\n",
       " [1, 789, 2, 839, 1745, 20, 168, 5644],\n",
       " [1, 1448, 487, 281, 1755],\n",
       " [26414, 8138],\n",
       " [484, 38978],\n",
       " [6479, 239, 144, 1916, 4058, 10, 17480, 42, 3495, 2081, 10713],\n",
       " [20, 2479, 384, 392],\n",
       " [143, 482, 49, 31226, 650, 2109],\n",
       " [4886, 6483, 6, 5309, 3478, 94, 2, 1, 96, 58, 6769, 6586],\n",
       " [223, 796, 3, 1021, 15840, 6, 173, 6901, 1034, 3, 1310],\n",
       " [43, 3936, 882, 600, 530, 8845, 6, 1784, 2335, 5213],\n",
       " [4867, 12, 17569, 56, 27, 806, 44, 64346],\n",
       " [1470, 37, 3999, 421, 1958, 3282, 58, 11794, 16, 2607, 910],\n",
       " [1124, 10, 1, 901, 2, 245],\n",
       " [1, 4095, 1328, 795, 25336, 6, 7, 596, 49465],\n",
       " [409, 78, 1411, 6, 1223, 1841],\n",
       " [1160, 17691, 27, 450, 33, 2994],\n",
       " [2882, 123, 798, 2335, 13, 6381, 1304, 1859, 9504],\n",
       " [1405, 346, 6, 4670, 253, 75, 1745],\n",
       " [27427, 112, 20, 1, 281, 3, 11524, 1311],\n",
       " [3366, 970, 3479, 264, 16, 38945],\n",
       " [1013, 617, 1307, 12, 2537, 6, 1420, 214, 13, 878, 4, 6439],\n",
       " [2373, 992, 4026, 6, 31, 4232, 3, 2396, 9485, 9087],\n",
       " [9390, 2567, 12, 811],\n",
       " [158, 2, 80, 56, 39, 1236, 4, 3755],\n",
       " [4559, 3864, 15, 1746, 518, 2673],\n",
       " [333, 7, 199, 2098, 2534, 6, 1238, 20, 1679],\n",
       " [1908, 9485, 1166, 33, 237, 601],\n",
       " [209, 2493, 10, 7, 1418, 1964],\n",
       " [3298, 562, 69, 39, 5079, 44, 1327, 3220],\n",
       " [109, 64, 1407, 26, 4075, 525, 3523],\n",
       " [3296, 161, 37, 21872, 26, 1838],\n",
       " [17503, 2236, 4, 287],\n",
       " [3050, 112, 20, 792, 1365],\n",
       " [7, 43, 472, 2524, 136, 11921, 1, 148, 1017, 87],\n",
       " [29, 19714, 5624, 2, 47809, 240, 25458, 4342, 6, 463, 1233],\n",
       " [23065, 20429],\n",
       " [148, 810, 499, 96, 2207, 46342, 4, 1072, 12841, 1250, 12, 778],\n",
       " [1, 55876, 1561, 70, 1, 1271, 2, 85, 337, 799],\n",
       " [1388, 27672, 3968, 729],\n",
       " [26657],\n",
       " [1, 49442, 23107],\n",
       " [207, 267, 215, 2003, 46962, 12968],\n",
       " [4056, 94, 1, 2206, 2, 684],\n",
       " [41791, 7022, 3355, 2452, 2588, 6, 528, 12, 52, 187, 7483, 38340],\n",
       " [1086, 110, 877, 9809, 33, 29877],\n",
       " [680, 285, 2591, 29, 5414, 365, 58, 18500, 9703, 1828],\n",
       " [2749, 27, 925, 626, 2, 11969],\n",
       " [5164, 13217, 12, 37618, 3993],\n",
       " [47, 2433, 3420, 1958, 410],\n",
       " [1, 469, 15, 907, 1521],\n",
       " [1745, 136, 1819, 659, 205, 419],\n",
       " [1, 14849, 12, 10668, 2375, 197],\n",
       " [21, 2533, 15, 967, 15751],\n",
       " [1246, 2095, 2413, 26, 3895, 3937, 21122, 227, 12766, 301, 608],\n",
       " [6, 2303, 7, 233],\n",
       " [2156, 2171, 3, 574],\n",
       " [13155, 31860, 5217, 26, 24529, 48883, 2, 816, 6489, 3138, 5757],\n",
       " [209, 33394, 27, 845],\n",
       " [1013, 10, 543, 20, 1465, 1766],\n",
       " [3657, 10, 76, 2836, 211, 1427],\n",
       " [20186, 10, 75],\n",
       " [28693, 1536, 8960, 997, 3, 32, 59, 12648],\n",
       " [1, 599, 219, 2, 1465],\n",
       " [314, 8143, 377, 2498, 14477, 33, 21, 186, 264],\n",
       " [1, 15136, 17478, 4149],\n",
       " [7520, 14178],\n",
       " [1545, 8630, 47, 1288, 609, 2, 1041, 3724, 4, 2812, 2, 17478],\n",
       " [57, 6, 23715, 7, 7341, 8237],\n",
       " [1, 62043, 27, 26845, 40704],\n",
       " [281, 390, 14392, 2159],\n",
       " [7, 490, 2042, 19072, 10, 9414, 45, 2690, 337, 378],\n",
       " [57, 6, 7261, 725, 1380, 2, 85, 1141, 427],\n",
       " [308, 1081, 87, 230, 101, 545, 2527, 3, 2753, 1796],\n",
       " [64, 67799, 232, 784, 6, 270, 12382, 4, 2994],\n",
       " [7428, 61, 1, 550, 2, 29, 2815, 10, 37, 13, 3527, 13, 28, 2515],\n",
       " [1109, 3061, 20, 632, 1151, 15, 2950, 9271, 3, 1643],\n",
       " [2797, 481, 31, 333, 148, 24749],\n",
       " [7, 848, 1657, 2532, 83, 1307, 20, 5961, 7, 2376, 2969],\n",
       " [5633, 12, 1, 599, 10951, 2, 1, 24981, 5770],\n",
       " [722, 7021, 38800, 10, 4013, 4, 18682, 3503],\n",
       " [1509, 5476],\n",
       " [12606, 1894, 10844, 1331, 1473, 4, 1833, 6, 523, 883, 2562],\n",
       " [64408, 1311, 2020, 1872, 6, 1903, 1662, 2906],\n",
       " [26396, 38807, 1866, 6680, 464, 4, 2945],\n",
       " [444, 484],\n",
       " [1, 3475, 472, 2602],\n",
       " [282, 5608, 328, 993, 3870, 50, 650, 531, 26, 104, 1174],\n",
       " [286, 810, 3611, 4544, 966, 27621, 15, 45, 7981, 254, 1135],\n",
       " [286, 750, 3221, 5777, 11641, 4, 16152, 496],\n",
       " [209, 1, 2446, 91, 482, 6, 1043, 320, 441, 10932, 9011, 1151],\n",
       " [7, 1464, 3786, 2, 1234, 5978],\n",
       " [21688, 1259, 99],\n",
       " [796, 1003, 27601, 2435, 3857, 112, 86, 12, 27793],\n",
       " [912, 12, 281, 3269],\n",
       " [1852, 1, 238, 20, 7, 1409, 6, 9211, 29305, 1259, 2949],\n",
       " [1141, 15281, 11549],\n",
       " [7, 6173, 180, 6, 2228],\n",
       " [57, 6, 2098, 6, 2459, 13, 7, 1397, 1536, 15, 76, 337, 3299],\n",
       " [17950, 341, 4, 760],\n",
       " [280, 149],\n",
       " [64256, 2579, 55596],\n",
       " [4624, 399, 864],\n",
       " [932],\n",
       " [2528, 8779, 24942],\n",
       " [1, 193, 2, 5, 1259],\n",
       " [3838, 6, 1899, 19414, 69, 31, 2073, 2, 819, 4, 12201, 4103],\n",
       " [209, 3194, 3502, 225, 2954, 73, 5, 469],\n",
       " [7733, 545, 3797, 61, 484, 11151],\n",
       " [52200, 3425],\n",
       " [1021, 2634],\n",
       " [158, 2, 1, 514, 501, 925, 634, 144, 680],\n",
       " [320, 7, 281, 486, 2, 7, 218, 223, 1252, 15226],\n",
       " [5994, 4586, 250, 499, 522],\n",
       " [2647, 291, 281, 3922, 225, 583, 150, 51, 5205, 94, 3, 807, 6, 2969],\n",
       " [223, 5113, 3470, 83, 31, 6955, 4232],\n",
       " [6875, 14401, 4668, 15, 751, 4494],\n",
       " [3366, 1, 4093, 2, 4303, 1271, 487, 14122],\n",
       " [1, 365, 2, 650, 10, 31226],\n",
       " [980, 18852, 13, 1, 320, 3004, 2, 4485, 10180],\n",
       " [1, 2828, 64, 3135, 64, 53, 899, 4, 232, 190, 618, 761],\n",
       " [1130, 12, 2000, 1, 241, 3114, 3, 1232, 7, 43, 337],\n",
       " [8194, 196, 1110, 10088, 8874],\n",
       " [9269, 469, 3631, 15, 188, 128, 885],\n",
       " [1536, 2, 16649, 1232, 2211, 6, 1266, 207, 267, 1105],\n",
       " [5243, 5653, 9363, 4, 1141],\n",
       " [1173, 3, 1, 1028, 7701, 2, 3836],\n",
       " [6256, 4, 254],\n",
       " [76, 155, 12090, 26, 709, 308, 4, 9984],\n",
       " [1324, 36606],\n",
       " [262, 12, 49544, 20, 3767, 945],\n",
       " [57, 6, 473, 7, 472, 994, 33, 850],\n",
       " [1479, 5837],\n",
       " [33628, 124, 1, 927, 2, 29, 1353],\n",
       " [967, 9314, 12, 1141, 5403, 936, 4925],\n",
       " [2537, 307, 543, 6, 19027, 15463, 34, 126],\n",
       " [67337],\n",
       " [20, 11660, 2750],\n",
       " [2893, 1, 258],\n",
       " [1, 167, 466, 12348],\n",
       " [7, 420, 15, 7, 3218, 2269],\n",
       " [1, 722, 7748, 4439, 2908, 10, 1089, 19736],\n",
       " [11932, 2, 8524],\n",
       " [10691, 3115, 56163],\n",
       " [8059, 11247, 20, 1, 282, 1869, 769],\n",
       " [29232, 2045, 27, 37, 13, 1983, 13, 97, 1299],\n",
       " [9563, 1, 241, 514, 2134, 12, 610],\n",
       " [292, 37, 6416],\n",
       " [9966, 1041, 15, 4280, 26, 2517, 2060],\n",
       " [345, 7, 1214, 5110, 1659, 254, 4, 34, 45114, 44486],\n",
       " [1944, 4, 1310, 2522, 2, 4343, 49666, 4830],\n",
       " [444, 10, 320, 29, 6377, 870, 2973, 995],\n",
       " [709, 308, 6, 5046, 867, 2003, 4, 1, 907],\n",
       " [8726, 34850, 247, 456, 5757, 26, 1, 90, 1836],\n",
       " [1634, 188, 5653, 1260, 4, 487, 211, 759, 94, 2, 725],\n",
       " [209, 34, 1065, 742, 1750],\n",
       " [7, 19905, 1161, 6, 3012, 586],\n",
       " [7, 1991, 2267, 5350, 7, 373, 113, 15945, 2580, 2638],\n",
       " [663, 21482, 20820, 1456, 479, 12, 16172, 82],\n",
       " [339, 7, 793],\n",
       " [13226, 1558, 1089, 5918, 131, 1091, 5, 427, 1602],\n",
       " [1923, 14438, 4814],\n",
       " [624, 4851, 4, 10244],\n",
       " [57, 525, 3, 1013, 18761, 1, 149, 4, 606],\n",
       " [28547, 254, 207, 112, 3322],\n",
       " [48, 64, 39, 7, 1069, 7736],\n",
       " [209, 223, 49683, 5806, 2503, 10, 7, 15685, 3708],\n",
       " [5085, 7756, 2659, 8846, 6, 244, 7794],\n",
       " [2134, 7334, 936, 2104, 760],\n",
       " [21469, 6022, 1, 957, 2, 1, 1342, 468],\n",
       " [209, 225, 97, 506, 4, 218],\n",
       " [2134, 7334, 1219, 27, 104, 15438, 15, 4595, 26, 33815],\n",
       " [11702, 479, 1245, 18323, 2, 9641, 6714, 6, 31, 843, 4, 1740, 3144],\n",
       " [3084, 3, 8495, 1047, 12, 281, 832, 4, 1141],\n",
       " [2872, 6237, 6, 5085, 6, 919, 6038, 9130, 70, 499, 90, 3257],\n",
       " [8351, 33889, 3150, 1166, 26, 15040, 4, 7, 3990, 684],\n",
       " [20210],\n",
       " [1, 1795, 549, 7756, 85, 341, 358, 492],\n",
       " [1310, 791, 6, 370, 1833, 4, 85, 2707],\n",
       " [1863, 21017, 20, 6466],\n",
       " [1, 164, 13210, 2, 64487],\n",
       " [1, 20415, 3028, 2152],\n",
       " [649, 3, 28416, 3911, 4, 49030],\n",
       " [196, 7, 3709, 4, 7053, 2909],\n",
       " [57, 8439, 2875, 18067, 7525],\n",
       " [17951, 3546],\n",
       " [2634, 648, 8530],\n",
       " [2528, 10, 7, 2211],\n",
       " [491, 8642, 254, 3950, 221, 2734, 3022, 996],\n",
       " [9266, 999, 3425, 10, 207, 213, 711, 1846],\n",
       " [57, 6, 173, 29, 10893],\n",
       " [3557, 1640, 1399, 2, 848, 4533],\n",
       " [1, 2394, 1972, 6, 1684, 24403, 22671, 239, 26, 4248],\n",
       " [16419, 21361, 274, 5127],\n",
       " [4163, 258, 7435],\n",
       " [11969, 12192, 1019, 3, 962, 1549, 3497],\n",
       " [333, 7, 59164, 23642, 15, 7, 726, 215],\n",
       " [2728, 2335, 4, 2885, 15, 359],\n",
       " [6299, 969, 2, 1, 3788, 34042, 433],\n",
       " [737, 6, 867, 3, 7500],\n",
       " [196, 1, 7730, 25430],\n",
       " [624, 99, 2, 14769, 2099, 4, 1, 148],\n",
       " [286, 8095, 214, 514, 4577, 26169, 13, 1129, 611, 819],\n",
       " [13269, 3277],\n",
       " [57, 6, 270, 12989, 13, 7, 190, 936, 211, 543, 598, 838],\n",
       " [421, 2188, 1196, 6, 183, 3557, 2649, 10053, 15, 356, 1072, 501],\n",
       " [8222],\n",
       " [9901, 1384, 1412, 518, 4247],\n",
       " [8161, 2648, 397],\n",
       " [10735, 86, 55055, 16, 4243, 1, 16066],\n",
       " [71, 901, 4609, 722, 690, 7694, 3, 5109, 2, 49638, 46938],\n",
       " [487, 362, 4, 1, 1559],\n",
       " [21, 791, 6, 31, 49, 3981, 34, 126],\n",
       " [63233, 40, 7, 43, 16144],\n",
       " [4820, 155, 26586],\n",
       " [1013, 18603, 9227, 859, 4387, 16, 6234],\n",
       " [29, 2381, 1161, 6, 13566, 16576],\n",
       " [7, 3955, 507, 6, 6764, 649],\n",
       " [57, 6, 4755, 1105, 101, 586, 5080],\n",
       " [441, 514, 2035, 2246, 6, 9821, 2, 338, 886],\n",
       " [78, 1, 17335, 26, 1, 1145, 288],\n",
       " [2378, 43392, 15, 667, 696, 9558],\n",
       " [919, 104, 7, 55030],\n",
       " [7377, 2, 85, 177, 787],\n",
       " [1449, 552, 9768, 40, 511],\n",
       " [2000, 7, 469, 33, 1, 2395, 2, 1, 223, 2134],\n",
       " [25332, 1658],\n",
       " [2016, 2, 25664],\n",
       " [875, 450, 2037, 2479],\n",
       " [1, 1491, 275, 2, 320, 4, 218, 10, 75],\n",
       " [4825, 1, 4624, 5007],\n",
       " [421, 83, 78, 4378, 18273, 10646, 6, 1348, 80, 4007, 15346],\n",
       " [282, 104, 8395, 20, 1954, 3544, 372, 6526],\n",
       " [133, 2, 484, 3305, 10, 7, 21341, 484, 12334, 12, 545],\n",
       " [2000, 1649, 18, 438, 1, 1610],\n",
       " [27111, 1124, 3, 1, 605, 1465, 765],\n",
       " [1, 45421, 876],\n",
       " [1, 376, 149, 3642],\n",
       " [10598, 2261, 5978, 2, 17953, 1869, 1250, 4, 2922],\n",
       " [342, 487, 222, 108, 759, 211, 2780, 96],\n",
       " [45229, 3355, 1715, 262, 12, 5159, 1669, 1371],\n",
       " [1228, 33097, 3, 1216, 2, 14799, 3026],\n",
       " [3611, 40, 7, 191, 469, 15, 45, 6751, 338, 3438],\n",
       " [4890, 528, 609, 12, 54, 1209, 21362, 4, 4790, 2620],\n",
       " [57, 143, 437, 7364, 229],\n",
       " [2265, 1, 165, 2, 1, 9351, 15780],\n",
       " [59, 6060, 123, 495, 110, 4378, 16054, 242, 6, 3085, 2157],\n",
       " [223, 271, 12091, 4632, 18297, 4520, 207, 267, 7600, 10738],\n",
       " [1, 14284, 42, 1741, 1517, 613],\n",
       " [43, 7097, 1370, 1539, 24749, 80, 211, 1, 1197, 2682, 1461],\n",
       " [145, 4267, 6004, 6, 4553, 82, 4, 5773, 2218, 12, 925, 6746],\n",
       " [1, 7055, 1514, 10, 214],\n",
       " [1649, 4, 64359],\n",
       " [7, 4819, 4, 1, 1789, 2, 1, 3830, 128],\n",
       " [38968, 15216, 1173, 4049, 3, 4612],\n",
       " [474, 6, 1046],\n",
       " [43, 1013, 835, 6429, 56136, 40, 76, 3358, 2967],\n",
       " [446, 668, 354, 6, 1645],\n",
       " [796, 18677],\n",
       " [209, 1, 468, 10, 22056],\n",
       " [57, 39128, 939, 211, 432, 7, 784],\n",
       " [1545, 3725, 328, 254, 365, 13, 120, 114, 3, 7938, 473],\n",
       " [162, 12043, 10, 200, 17480],\n",
       " [295, 23793, 43195, 18, 1637, 4201, 3524],\n",
       " [27190, 37, 8729, 5036, 696, 6, 28446, 705],\n",
       " [3798, 12, 87, 1285],\n",
       " [7, 707, 398, 891, 12, 759, 3797, 20, 1061, 4396],\n",
       " [209, 1141, 12, 3094, 341],\n",
       " [38730],\n",
       " [1, 1688, 779, 18, 40, 441, 514, 20897],\n",
       " [215, 2003, 12, 1127, 269],\n",
       " [293, 3715, 1563, 109, 4160, 369, 20, 1, 3515, 465],\n",
       " [438, 610, 14832, 34],\n",
       " [57, 1, 38361, 22, 437, 3, 209, 28, 22, 29, 6259, 4600],\n",
       " [1388, 601, 3564, 5080, 97, 225, 31, 3999],\n",
       " [12747, 40, 3533, 29, 359, 6, 269, 775, 3086],\n",
       " [936, 830, 33, 27190],\n",
       " [5, 5233, 4987, 6, 1210, 7729, 2576],\n",
       " [1717, 1370, 530, 29, 1467, 7503, 6, 2722, 20, 4, 5743, 16806],\n",
       " [3390, 5],\n",
       " [12747, 4288, 3043, 6, 15840, 15, 920, 1076, 211, 101, 205, 112],\n",
       " [2542, 1678, 6, 1177, 247, 456, 994, 98, 1561, 247],\n",
       " [38866, 10, 1, 369, 7445, 4617, 4, 1958, 2458],\n",
       " [1950, 11273, 4869, 63, 77, 342, 14979, 3, 9119, 264],\n",
       " [24903, 6, 751, 32903, 2875, 75, 21, 82],\n",
       " [842, 52, 70, 487, 1422, 3715],\n",
       " [1044, 83, 1309, 680, 6, 1, 256, 5744],\n",
       " [17041, 1939, 3, 112, 649, 1582, 12, 52317, 7877],\n",
       " [3709, 18, 136, 345, 1, 984, 15860, 399, 214, 33, 76, 913],\n",
       " [970, 6879, 4247, 15, 453, 1615, 3, 14269, 6417],\n",
       " [297, 225, 37, 3581, 598, 159, 20, 414],\n",
       " [4890, 751, 4, 20, 43, 180, 6, 3268, 4363, 2852],\n",
       " [3287, 13915, 8927, 1937, 492, 6, 32, 921],\n",
       " [20, 1, 33296, 205, 5061, 769],\n",
       " [57991, 65008, 27, 1, 54, 4343, 3129, 95],\n",
       " [2563, 1034, 222, 17285],\n",
       " [4752, 1972, 227, 555, 45, 287, 6, 31, 20, 1780, 3, 870, 16, 17023],\n",
       " [733, 6, 6659, 313, 14625],\n",
       " [2564, 20, 6, 1771, 4, 1809],\n",
       " [1271, 2, 207, 267, 190, 3, 1423, 20, 1, 1366, 522],\n",
       " [525, 2437, 2, 6000, 2523, 23401, 4, 602],\n",
       " [40622],\n",
       " [1, 2018, 1051, 2, 1, 28176, 18670, 16, 552, 18511],\n",
       " [101, 1, 7247, 7012, 3709, 6, 1578, 94, 26, 4846],\n",
       " [701, 549, 11661, 62, 247, 456, 3138, 427, 10945],\n",
       " [50071, 5498, 27, 1323, 239, 6, 3637, 92, 1, 1366, 1879, 45, 180],\n",
       " [115, 3, 207, 267],\n",
       " [1219, 6, 2743, 6, 173, 1247, 84, 1863, 3, 4971, 115],\n",
       " [11854, 33, 1013],\n",
       " [15903, 5576, 31080, 12, 12132, 5644],\n",
       " [6783, 4520],\n",
       " [15795, 11547, 2, 5321, 1597],\n",
       " [93, 2771, 10, 11417, 6, 39, 883, 4681, 2127, 16, 15042],\n",
       " [57, 7411, 115, 10, 104, 30296],\n",
       " [57, 456, 3912, 292, 30925],\n",
       " [14758, 4253],\n",
       " [1, 253, 144, 1, 11122, 2485],\n",
       " [16446, 1133],\n",
       " [143, 27, 52, 6172],\n",
       " [143, 1547, 23920, 787, 33, 4882],\n",
       " [442, 2239, 15460, 36318, 1465, 2335],\n",
       " [4990, 903, 26, 1, 1383, 3, 1312, 6, 1, 1510],\n",
       " [286, 40, 947, 7, 2470, 43, 856, 4932],\n",
       " [1019, 390, 21996, 6, 6273, 368, 308, 3, 112, 1365],\n",
       " [7, 539, 8430, 5399, 223, 4, 7, 3936],\n",
       " [64, 11847, 1, 54, 255, 16854, 20, 4085],\n",
       " [1781, 11966, 1724, 4646, 2730, 3, 4058, 8782, 58, 4610],\n",
       " [7, 507, 6, 1, 674, 509],\n",
       " [57, 6, 9513, 26, 1, 22527, 7543, 5212, 6, 1, 22527, 1003],\n",
       " [57, 6, 2890, 409, 70, 1216],\n",
       " [15450, 9558, 27, 277, 17696],\n",
       " [1688, 779, 77, 1849, 112, 16827, 26, 1937, 1239, 3, 607, 112],\n",
       " [942, 1785, 3057, 11225, 6, 6889, 3309, 2917, 70507, 40759],\n",
       " [155, 27419],\n",
       " [64, 103, 232, 177, 1371, 5159, 3453],\n",
       " [341, 4315, 26589, 15, 928, 64380],\n",
       " [33815, 13, 55772],\n",
       " [10, 29, 309, 631, 241, 12, 97, 4, 3503],\n",
       " [842, 1141, 16, 540, 7, 228, 1459],\n",
       " [1228, 811, 40, 4964, 19, 471, 56, 41, 5515, 6, 8721, 321],\n",
       " [7555, 2, 1, 26709],\n",
       " [16025, 3394, 27, 28901, 3838, 6, 23464],\n",
       " [282, 31667, 951, 3836, 20, 1710, 3, 83, 200, 345, 7, 1696],\n",
       " [45138, 341, 13, 7, 3422, 1992],\n",
       " [32448, 1, 4690, 399, 15, 43, 4690, 2746, 132, 3, 197, 81],\n",
       " [27253, 1605],\n",
       " [6280, 3732, 3, 1, 190, 1488, 1720],\n",
       " [28120, 4471, 11214, 3424, 6, 6488, 42172, 15, 51149, 5509],\n",
       " [55669, 810, 2827, 10, 1111, 6, 13460, 2544, 13, 159, 369, 126],\n",
       " [232, 632, 514, 17863],\n",
       " [282, 733, 6, 115, 724, 2246, 6, 3033, 694, 6240],\n",
       " [1849, 3138, 2718],\n",
       " [223, 726, 359],\n",
       " [13949, 7297, 20, 11074, 30, 8434, 20, 4783, 6278, 1122],\n",
       " [4189, 9973, 27, 31094, 3277, 4, 1, 514, 2136],\n",
       " [1, 1114, 10, 37, 405],\n",
       " [112, 6968],\n",
       " [1, 54, 260, 412, 12, 489, 1107, 4, 328, 63],\n",
       " [1264, 11920, 10, 70, 1089, 1510, 15, 7, 3084, 10135],\n",
       " [1524, 975, 39966, 4614, 1678, 456, 2320, 1103],\n",
       " [232, 503, 3061, 7486],\n",
       " [109, 1013, 225, 161, 369],\n",
       " [21970, 3, 17170, 358, 7957, 501],\n",
       " [2598, 1260, 26, 5825, 4668],\n",
       " [1863, 3, 612],\n",
       " [484, 3305, 8748, 5367, 9745, 1875, 2, 10843, 4115, 7729, 2659],\n",
       " [1068, 1562],\n",
       " [1, 2994, 795, 16176, 32308],\n",
       " [58511, 70, 397, 4, 1, 20431],\n",
       " [491, 8642, 3950, 4087, 45, 599, 6289, 4, 254, 7, 380, 1379, 695],\n",
       " [4119, 2437, 2, 14086, 848, 1534, 6, 1001, 450, 4, 8748],\n",
       " [387, 2207, 4, 5565, 27, 7327, 4899, 556, 6, 1124],\n",
       " [1, 655, 1555, 144, 1465],\n",
       " [1096, 7, 723, 653],\n",
       " [919, 13949, 5559, 2002, 26, 19975, 85, 2517],\n",
       " [9135, 15509],\n",
       " [329, 3, 997],\n",
       " [43, 283, 123, 40, 49, 5587, 12104, 67, 12705, 12, 7169],\n",
       " [320, 9269, 13052, 382, 802],\n",
       " [44412, 414, 643, 4819, 4, 2396, 16997, 2, 775, 3086],\n",
       " [7, 18764, 846, 36605, 4465, 40, 3482],\n",
       " [14466, 2418, 2208],\n",
       " [5570, 2, 1601, 7022, 325, 12, 1, 6934, 2859],\n",
       " [223, 10, 2530, 328, 112, 33, 7, 26847, 850],\n",
       " [722, 2790, 551, 26, 1, 59600, 6, 28767, 1350],\n",
       " [109, 329, 22, 125, 256, 63, 9485, 1166, 41, 13, 160, 13, 366],\n",
       " [12917, 15247, 2899, 89, 232, 63, 33, 5085, 13, 7, 37691],\n",
       " [10536, 1710, 936, 802],\n",
       " [1, 420, 2, 6377],\n",
       " [13513, 149, 1465, 4008, 12999, 58, 2869, 44339, 4264, 6157],\n",
       " [1, 2392, 1266, 4004, 4, 37, 940, 6, 751, 111, 63, 15055],\n",
       " [7, 4271, 507, 20, 1328],\n",
       " [1, 71, 607, 814, 10, 4757, 45, 207, 267, 4646, 549],\n",
       " [28756, 9681, 1, 674, 10338, 20, 23377, 1250, 5023],\n",
       " [57, 750, 27, 101, 368, 308, 6, 6205, 6, 1583],\n",
       " [408, 2259, 18, 54, 2, 328, 3137, 2075, 136, 31, 1750],\n",
       " [816, 1791, 3, 6447, 15, 218, 11456, 2, 1, 816],\n",
       " [64, 645, 232, 21, 126, 359, 1944, 6241, 4, 21, 778],\n",
       " [1477, 1160, 80, 339, 536, 4, 1, 1854],\n",
       " [57, 85, 18096, 5032, 112, 239, 6, 286],\n",
       " [4559, 12247, 1275, 5445, 33, 850, 101, 359],\n",
       " [4802, 2, 101, 4815, 2914, 1643],\n",
       " [12665, 1886, 3648],\n",
       " [4852, 2, 7, 2423, 7073],\n",
       " [1, 183, 2, 1397, 6978],\n",
       " [1382, 506, 1869, 1250, 15, 1494, 7411],\n",
       " [2659, 9299],\n",
       " [1013, 6, 2671, 94, 9172, 12, 650, 531],\n",
       " [3703, 22522, 40, 55, 14046, 1102, 12, 8750, 82],\n",
       " [1039, 4259, 2, 10181, 1006],\n",
       " [9448, 881, 4, 1311, 10248, 4152, 2, 2208, 308],\n",
       " [1661, 2829, 2, 1251, 23068, 22453],\n",
       " [1, 26276, 758, 20, 329],\n",
       " [7, 9471, 725, 8767, 87, 4, 3305, 849],\n",
       " [57626, 22732, 4, 6521, 2830, 20, 1212, 6, 1584, 49, 883, 1473],\n",
       " [7, 11286, 913, 4586],\n",
       " [684, 342, 6483, 6695],\n",
       " [5333, 2, 463, 3607, 8575, 56, 33, 5502, 6, 916, 12, 369, 1517],\n",
       " [2207, 27, 6331, 1280, 257, 15, 3556],\n",
       " [1520, 225, 37, 284, 3450],\n",
       " [3268, 24146, 5178, 4, 1291, 1151, 12, 155],\n",
       " [612, 7321, 6, 803, 86, 5219, 5937, 3, 11777, 1588, 12, 1, 472, 275],\n",
       " [57, 3142, 1392, 10, 104, 62, 4, 1, 2872, 90],\n",
       " [1745, 97, 225, 583, 12, 87, 284],\n",
       " [1, 9363, 2, 221],\n",
       " [13098, 1, 23428],\n",
       " [704, 3, 700, 853, 921, 1791, 1666, 2872],\n",
       " [875, 28630, 18, 5819, 5104],\n",
       " [2018, 308, 1755],\n",
       " [13223, 3074, 13077, 4, 1141],\n",
       " [359, 1986, 765, 3503],\n",
       " [1959, 10, 2794, 13184, 4, 3, 4078, 45, 185, 3, 13051, 853],\n",
       " [3218, 4282, 6, 610],\n",
       " [2251, 49729, 4, 1185, 499, 2430, 257],\n",
       " [7, 1689, 6872, 2, 1, 47, 2244, 4, 1, 4872],\n",
       " [2363, 5924, 144, 680],\n",
       " [10768, 3507, 136, 56606, 113, 12, 5987, 2, 82],\n",
       " [1774, 10481, 7121, 6036, 20, 113, 3, 245, 20, 2474, 4379],\n",
       " [5253, 17060, 4, 7819, 2116, 846],\n",
       " [9316, 3, 10905, 1638, 232, 337, 281, 400],\n",
       " [1447, 1385, 2, 499, 811, 2477, 1962, 6, 2071, 696, 6, 1, 9997],\n",
       " [9853, 4432, 5008, 3, 3013, 2281],\n",
       " [1549, 2991],\n",
       " [57, 6, 1978, 1401, 85, 113, 211, 1962],\n",
       " [209, 1, 294, 326, 1972, 6, 763, 16719, 20, 2208, 3610],\n",
       " [5924, 3, 3422, 4710],\n",
       " [57, 6, 1410, 1411, 20, 1, 180, 6, 1528],\n",
       " [7, 653, 12, 2363, 2522, 2, 15734, 4972, 4, 43399],\n",
       " [185, 912, 12, 1710, 1520],\n",
       " [57, 6, 173, 85, 177, 5008],\n",
       " [1679, 6, 1303, 14026, 1784, 4552, 12639],\n",
       " [1, 253, 12, 840, 22162],\n",
       " [4706, 345, 7, 570, 1420, 4, 16673, 726, 215, 3411],\n",
       " [6039, 9322, 1447, 876],\n",
       " [1, 1453, 20, 46825, 567, 5263],\n",
       " [9414, 4248],\n",
       " [11921],\n",
       " [7702, 5804, 5454, 15, 1470, 1869, 17300],\n",
       " [750, 528, 47, 4, 205, 609, 2, 57, 5800, 156],\n",
       " [3390, 5433, 2738, 13, 295, 2699, 346, 638, 271, 10, 29, 9941],\n",
       " [29963, 785, 345, 7229, 5554, 6572],\n",
       " [33803, 6384, 45, 5847, 1918],\n",
       " [2750, 12, 112, 17824],\n",
       " [3819, 95, 647, 2, 18120],\n",
       " [1, 9049, 1830, 1, 157, 2296, 901, 2, 1469, 2, 2872],\n",
       " [830, 65436, 127, 1846, 12, 155, 123],\n",
       " [57, 6, 506, 7, 1716, 3636, 6702, 2928],\n",
       " [1013,\n",
       "  4992,\n",
       "  5109,\n",
       "  18,\n",
       "  2537,\n",
       "  10,\n",
       "  4642,\n",
       "  271,\n",
       "  33,\n",
       "  1216,\n",
       "  2,\n",
       "  15540,\n",
       "  4,\n",
       "  9677,\n",
       "  11634],\n",
       " [1983, 12974, 64353, 3231, 42995],\n",
       " [1199, 2899],\n",
       " [14205, 10, 214],\n",
       " [7, 1291, 1214, 368, 12, 1, 22519],\n",
       " [1181, 5411, 18, 3355, 15226, 5320, 6, 85, 402, 16167],\n",
       " [43428, 369, 1149],\n",
       " [1172, 1421, 20, 1181, 10, 29, 7230, 12, 5710],\n",
       " [5874, 211, 758, 8850, 10, 934, 20, 838, 1521],\n",
       " [101, 359, 6, 6993, 1081, 257],\n",
       " [57, 4044, 645, 75, 1105, 3, 723, 6499],\n",
       " [43, 2231, 284, 4462, 97, 453, 33, 9641, 40208],\n",
       " [1145, 288, 376, 325],\n",
       " [3166, 3319, 85, 112, 15],\n",
       " [205, 11891, 947, 20, 1528],\n",
       " [1, 1491, 629, 2, 190, 6590],\n",
       " [13428, 3, 7, 17213, 2, 195, 1311, 26, 150, 1, 1780],\n",
       " [7, 13241, 17201, 1228, 14285],\n",
       " [1, 2156, 27633, 2634],\n",
       " [3458, 10, 214],\n",
       " [57, 6, 2369, 13356, 4, 72, 907, 264],\n",
       " [37, 277, 182, 7748],\n",
       " [43, 1810, 2, 812, 3351, 4645, 6, 2215, 63, 4292],\n",
       " [7, 2829, 2, 7944, 3634, 113, 2316, 43, 2810],\n",
       " [7878, 884, 183, 936],\n",
       " [6407, 2807, 217],\n",
       " [11261, 15, 3455],\n",
       " [1, 2439, 6, 320, 7, 622, 726, 215],\n",
       " [3206, 4, 19676, 148, 10, 27557, 1477, 6, 10536, 264, 1415, 67, 28, 535],\n",
       " [12979, 70, 284, 257],\n",
       " [18857, 2620, 4543],\n",
       " [7, 675, 2, 14316],\n",
       " [356, 4170, 5325, 12, 4449, 6, 6463, 148, 551, 3432],\n",
       " [684, 634, 6, 13190, 808, 861, 3233, 6, 542, 126],\n",
       " [1228, 811, 8630, 951, 1082, 3357, 12, 68231],\n",
       " [2590, 18098, 3523, 2490, 1649],\n",
       " [1, 7371, 155, 1445, 1094],\n",
       " [209, 1, 545, 2301, 10, 1, 185, 2301],\n",
       " [7, 43, 1428, 769, 15, 76, 1175, 566, 10, 13, 2396, 13, 7, 3242, 9259],\n",
       " [30284, 26124, 974],\n",
       " [925, 207, 267, 3529, 6, 369, 447, 15, 1, 8039, 87],\n",
       " [57, 6, 8085, 85, 26385, 1916, 581],\n",
       " [5085, 5109, 8459, 200, 104, 62, 6, 1784, 80, 20, 247, 456],\n",
       " [578, 207, 36424, 4, 85, 230, 1559],\n",
       " [694, 1513, 951, 2517],\n",
       " [295, 184, 3898, 18393, 173, 33, 898, 3, 57, 6, 5803, 117],\n",
       " [49652, 644, 3929, 11369, 13, 1903, 3, 7, 520, 2, 1, 859, 2, 3516],\n",
       " [48681, 12234, 26136, 7379, 2, 17543],\n",
       " [59358, 292, 512, 64, 367, 544, 401],\n",
       " [1, 34660, 128, 4495],\n",
       " [348, 22, 1750, 70, 6430],\n",
       " [27663, 433, 241, 4, 85, 921],\n",
       " [32078, 5109, 2, 2031, 36352, 3, 1488, 4315],\n",
       " [2426, 1698, 6, 1383, 8367, 2949, 784, 1279, 4, 8488],\n",
       " [1, 169, 905, 443, 1, 175, 96],\n",
       " [57, 5085, 3, 223, 4964, 1, 722, 499, 4391, 368],\n",
       " [359, 136, 173, 294, 37351, 9317, 450],\n",
       " [1106, 18, 435, 610, 82, 6, 842],\n",
       " [101, 7, 7392, 1733, 15, 1, 1578, 11022, 4, 723],\n",
       " [23084, 174, 796],\n",
       " [13668, 3276, 5166, 427],\n",
       " [4706, 528, 609, 2, 2493, 8138, 4, 758, 12, 1, 47, 63],\n",
       " [29, 2261, 507, 6, 25769],\n",
       " [534, 2, 1470, 20694, 533, 9038],\n",
       " [7372, 39726, 10415, 1, 3426, 1934, 4, 27186],\n",
       " [7878, 405, 2134, 936],\n",
       " [23, 647, 18, 8263, 7, 43, 2724, 2511],\n",
       " [63, 1318, 5001, 737, 20, 545],\n",
       " [3892, 1679, 1465, 13129],\n",
       " [1, 8889, 768, 920, 64, 1444, 6, 837, 34, 126],\n",
       " [10, 3758, 73, 6935, 242, 6, 1, 399, 559],\n",
       " [1, 16067, 2, 2820],\n",
       " [1, 238, 795, 15610, 437, 28, 12, 34, 2830],\n",
       " [600, 12179],\n",
       " [1009, 47, 1399, 3, 507, 12, 320, 936, 3391, 3, 757],\n",
       " [4140, 11195, 1299, 1465, 83, 21350, 3541],\n",
       " [286, 870, 3, 3923, 655, 7, 7720, 112, 478, 4, 24, 778],\n",
       " [66, 716, 246, 10, 2183],\n",
       " [12173, 26, 13836],\n",
       " [7624, 323, 10, 1175, 26, 1021, 6, 28178],\n",
       " [2031, 2148, 1347, 5709, 4576, 3439, 33, 43368],\n",
       " [2846, 2537, 277, 381, 34, 70, 1013, 1103],\n",
       " [155, 1046, 40, 645, 182, 1782, 33, 1598],\n",
       " [404, 29986, 3922, 2605, 12, 1962, 6, 40337, 32, 9941],\n",
       " [6027, 3994, 10, 179, 6, 4436, 1194, 5523, 2109, 94, 2, 1, 293],\n",
       " [333, 1, 54, 2, 282, 2032, 165],\n",
       " [70459, 10, 214],\n",
       " [2846, 2537, 69, 979, 2086, 7251, 92, 1013, 10, 31115, 26, 362, 995],\n",
       " [484, 12334, 12, 545, 15, 6043, 993, 1516, 12, 484, 1477],\n",
       " [43, 3226, 20, 22085, 3, 18584, 30292, 12, 16689, 4, 286],\n",
       " [7, 404, 525, 1353, 1972, 6, 438, 97, 173, 85, 177, 863, 399],\n",
       " [24, 2306, 18, 406, 80, 367, 4387, 27, 7365],\n",
       " [57, 6, 179, 86, 36657, 12, 2973],\n",
       " [359, 7638, 92, 3, 66, 1961, 83, 830, 11841, 4456],\n",
       " [320, 7, 1869, 399, 4, 2070, 2539, 101, 73, 2117, 3, 1834],\n",
       " [19508, 21105, 4697, 971, 16, 1272, 2, 2011],\n",
       " [1, 43, 283, 264, 103, 7, 5233, 8329, 1376, 15, 45, 514, 3942],\n",
       " [1, 6609, 165, 2, 2202, 1063],\n",
       " [1716, 8003, 15, 13922, 3, 17236],\n",
       " [25733, 2503],\n",
       " [6814, 21479, 1105, 6, 45, 38959, 4743, 399],\n",
       " [57, 600, 2058, 29, 16197, 424, 323, 61, 967],\n",
       " [22816, 1245, 349, 112, 36292, 586, 542],\n",
       " [64, 1298, 28012, 3, 7309, 97, 225, 31, 598],\n",
       " [9135, 4925, 377, 15, 1, 43, 281, 3668, 18472, 10, 123, 439],\n",
       " [2831, 232, 1331, 6, 1, 907, 424],\n",
       " [10582, 810, 335, 5924, 27, 9781, 6, 2933, 2, 90],\n",
       " [1, 6254, 1516, 11880, 715, 538, 3, 362],\n",
       " [43286, 4450, 86, 85, 487, 222],\n",
       " [3394, 8179, 542, 1166, 2, 4068, 26, 1465, 8155],\n",
       " [1382, 3221, 47, 6612, 866, 18013, 1430, 3360, 4, 6513],\n",
       " [277, 793, 540],\n",
       " [7, 507, 12, 1089, 651, 15, 633, 4089],\n",
       " [109, 27, 15685, 5080, 3, 57, 6, 919, 101, 117],\n",
       " [320, 7, 5825, 22525, 4, 1477, 1359, 30, 299],\n",
       " [3433, 12264, 627, 6014, 4847],\n",
       " [1, 13730, 49645, 4132, 214, 2168, 1353, 3428],\n",
       " [148, 3672, 3, 11277, 843, 4, 2872],\n",
       " [7436, 3, 5144],\n",
       " [1430, 2143, 4258, 2778, 14756],\n",
       " [43, 4794, 2435, 3, 1, 3359, 2, 11595, 16407],\n",
       " [24030, 1304],\n",
       " [35900, 52704, 6, 1757, 402, 46362, 3, 1, 1610],\n",
       " [1689, 1540, 2, 744, 30796],\n",
       " [113, 4, 1888],\n",
       " [1, 17850, 2, 1, 1765],\n",
       " [1, 17160, 368],\n",
       " [13780, 20793],\n",
       " [11008, 205, 2132, 509, 4419, 6, 1991, 7052, 3391],\n",
       " [1, 27190, 1633, 7563],\n",
       " [16074, 3, 9722],\n",
       " [4803, 6, 967, 33646, 34707, 328, 1993, 779],\n",
       " [4423, 49308, 1, 9378],\n",
       " [3579, 27, 22705, 6, 24190, 85, 1397, 2398],\n",
       " [38957, 1863, 1060, 3857, 607, 112, 6, 441, 514, 501],\n",
       " [4169, 271, 10, 333, 7049, 18, 807, 61, 282, 2075],\n",
       " [3159, 287, 40, 2538, 1, 1657, 795, 1759, 2663, 3, 676, 587],\n",
       " [1021, 12740, 3631, 248, 4738, 2, 222, 582, 26, 45, 177, 1063, 8114],\n",
       " [209, 3, 57, 9347, 10, 200, 62],\n",
       " [221, 843, 1, 9911, 2, 5458],\n",
       " [2925],\n",
       " [47301, 1279, 20, 247, 456, 1839, 6, 402, 11932, 6159],\n",
       " [8745, 5998, 15, 607, 2106],\n",
       " [33815, 292, 2971, 5001, 6, 3067, 7, 2659],\n",
       " [7, 324, 4000, 6, 320, 7, 800, 5847, 337, 378],\n",
       " [2882, 52474, 4057, 2616, 17470, 6, 1559],\n",
       " [7, 363, 7966, 2, 709, 308, 12, 24768, 112],\n",
       " [472, 218, 653, 2, 348],\n",
       " [671, 257, 52, 1, 180, 214],\n",
       " [223, 1542, 428, 1479, 2492, 1, 499, 1873, 2, 2872],\n",
       " [1282, 64410],\n",
       " [341, 5664, 18113, 3937, 3832, 2656],\n",
       " [38490, 1410, 7741, 2, 1893, 2, 3708, 5537, 2, 1041, 4341, 153, 126],\n",
       " [5332, 41294, 10, 94, 2, 6519, 3, 2923, 12, 32, 369, 939],\n",
       " [1, 948, 1353],\n",
       " [3247, 5933, 529, 58, 1606, 12325, 47364],\n",
       " [504, 1843, 2911, 15723, 1152, 881, 12, 408, 20, 32928, 2643],\n",
       " [308, 504, 89, 1, 176, 71, 90],\n",
       " [8313, 1878],\n",
       " [33605, 1637, 1803, 6, 8233, 141, 51, 1901, 6, 1721, 680],\n",
       " [2846, 2537, 34716, 65167, 155, 1046],\n",
       " [11204, 1329, 557],\n",
       " [633, 9036],\n",
       " [1470, 1903, 7919, 41708, 7450, 4119, 12, 401, 4040, 3246],\n",
       " [3390, 643, 45, 47, 1420, 61, 1, 6534, 468],\n",
       " [68, 2218, 3966],\n",
       " [1155, 12, 980, 222],\n",
       " [920, 791, 6, 995, 112, 4, 361, 2852],\n",
       " [5085, 10, 13169, 525, 32857, 13, 45, 7052, 3358, 87],\n",
       " [4682, 725, 696, 15, 29, 12587, 1468],\n",
       " [7, 47, 1001, 33, 1, 43, 7761, 281, 7481, 3, 948, 230, 830],\n",
       " [1208, 7046, 931, 453, 7, 11698, 10162, 61, 1282, 931, 453, 10162],\n",
       " [47736, 80],\n",
       " [33815, 934, 29, 3842, 50275, 15, 672],\n",
       " [1465, 1294, 21970, 1260, 12, 5158],\n",
       " [15285, 19437, 2100, 6, 8233, 75, 3390, 1260, 4610, 4, 343],\n",
       " [184, 2539, 67833, 16144, 4898, 6858],\n",
       " [2061, 85, 177, 1021, 990, 3503, 3842],\n",
       " [282, 341, 358],\n",
       " [31365, 20, 1, 96, 2, 1465],\n",
       " [444, 3647],\n",
       " [1, 18296, 559, 3, 245, 69, 428, 4, 1, 146, 784, 496],\n",
       " [49652, 10, 1621, 76, 801, 1526, 12, 7, 15631],\n",
       " [5556, 1342, 5081, 43, 4867, 12, 839, 103, 15, 9269, 359],\n",
       " [4878, 1415, 15, 6065],\n",
       " [359, 83, 173, 85, 2012, 11026],\n",
       " [618, 14129],\n",
       " [4009, 4890, 528, 18, 11, 19048, 69, 31, 922, 293],\n",
       " [7, 1683, 1019, 15, 7, 4040, 378],\n",
       " [53567, 1318, 901],\n",
       " [24473, 8355],\n",
       " [40587, 2, 14551],\n",
       " [5891, 15344, 6, 1677, 1, 1340, 2, 5510, 7208],\n",
       " [402, 1884, 27, 6780, 1408, 1320, 2792, 6153, 695],\n",
       " [16716, 1625, 499, 11634, 75, 45, 839, 70, 1873, 2, 2872],\n",
       " [1175, 20],\n",
       " [2667, 149, 3645, 9355],\n",
       " [3871, 24294, 10172],\n",
       " [55690],\n",
       " [4119, 2437, 2, 11192, 20, 1423, 8748, 448],\n",
       " [3084, 19033, 3524, 109, 4160, 6, 85, 222, 66, 97, 78, 72, 2765, 1122],\n",
       " [772, 80, 48, 11672, 97, 6, 270, 1, 1813, 17659],\n",
       " [754, 2, 1, 3503, 726, 207, 267, 190, 2104],\n",
       " [143, 410, 7, 7581, 1163, 6, 2728, 7, 767, 2, 85, 1423, 1683],\n",
       " [282, 2020, 43, 11559, 427, 3, 647, 12, 17831],\n",
       " [1017, 11607],\n",
       " [6149, 2, 2798, 8664, 18339, 451, 2548, 13407, 995],\n",
       " [1013, 8095, 94, 14277, 75, 34550, 900],\n",
       " [50909, 6714, 1757, 454, 7, 2066, 2, 1, 148, 775, 33571],\n",
       " [3390, 10, 123, 7, 11430, 2, 1, 15245, 27134, 323],\n",
       " [223, 10, 543, 6, 7733, 1091, 15, 484],\n",
       " [1419, 2, 4681, 27, 2127, 3407, 3, 76, 5, 48, 919, 117],\n",
       " [10244, 3865, 7, 13199, 915, 4, 5490],\n",
       " [444, 1317, 6, 1401, 2339, 262],\n",
       " [11025, 2741, 3840, 459],\n",
       " [282, 4855, 2483, 1599, 87, 166, 3753, 8206, 399],\n",
       " [3748, 360, 2, 760],\n",
       " [36683, 103, 2043],\n",
       " [32081, 3400, 4710, 2, 4747, 3, 7313],\n",
       " [779, 6, 27475, 1, 30447, 2, 991, 2, 27339, 12, 18983, 499, 4856],\n",
       " [47, 1066, 26, 29231, 27, 1323, 20, 569, 35661],\n",
       " [6, 3012, 26, 487],\n",
       " [3242, 5933, 5008, 287],\n",
       " [1, 4340, 2, 992, 3293],\n",
       " [821, 2, 1, 90, 4, 2872],\n",
       " [34498, 13, 7, 1900, 1376],\n",
       " [20716, 7, 6157],\n",
       " [107, 304, 4813, 2218],\n",
       " [27790, 600, 3812],\n",
       " [1417, 287, 48, 5188, 9746, 1186, 5688, 582, 4, 50, 409],\n",
       " [1, 14049, 1277, 2, 6122, 25097],\n",
       " [6931, 27, 1, 365, 42, 38, 7, 11261],\n",
       " [7614, 545, 3, 484, 3797],\n",
       " [1237, 2, 5686, 4, 7, 1559],\n",
       " [35265, 4, 7, 18314, 15019, 3290],\n",
       " [282, 6971, 3, 27356, 45, 733, 6, 549, 1212],\n",
       " [57, 6, 8085, 85, 1021, 12, 1026, 3523],\n",
       " [791, 6, 14832, 85, 2762, 7576, 529],\n",
       " [359, 390, 40, 914, 3139, 6, 2303, 5636],\n",
       " [43, 1958, 3669, 3498, 3, 1, 8346, 514, 2041, 15, 4663, 5341],\n",
       " [602, 810, 59707, 48, 31, 12866, 448, 92, 36, 2911, 253],\n",
       " [3221, 1, 19745, 2, 1809],\n",
       " [2909, 487, 323, 61, 7, 314, 12176, 154, 1, 7509],\n",
       " [2194, 48, 31, 12208],\n",
       " [1, 183, 2, 40266, 10, 1217, 461],\n",
       " [36673, 3709, 1289, 11785, 696, 6, 2339, 796, 1365, 3993],\n",
       " [2761, 10744, 3, 393, 115],\n",
       " [10140, 930, 1, 73, 3829, 4, 2872],\n",
       " [376, 197, 2129, 57, 18503, 115, 3, 7508, 19030, 101, 7, 59167, 5837],\n",
       " [209, 6753, 30973, 4, 1, 907],\n",
       " [57, 6, 523, 7, 12413, 1047, 378, 12, 417, 128, 1634],\n",
       " [3716, 1342, 10350, 33, 6902],\n",
       " [5988, 12, 5988],\n",
       " [1, 1082, 2, 22093, 6231],\n",
       " [5008, 26238, 136, 38751, 6369],\n",
       " [15745, 7961, 3440, 8460, 211, 4680, 3440],\n",
       " [14481, 20589],\n",
       " [7, 1946, 99, 2, 7115, 4, 221, 768],\n",
       " [4005, 292, 850],\n",
       " [10900, 1, 71, 4, 3503],\n",
       " [1124, 9591, 23715, 3784, 1499, 165, 1330],\n",
       " [13382, 29, 13547, 29023, 20, 1, 6030],\n",
       " [143, 742, 1110, 1, 455, 775, 3086, 6588],\n",
       " [173, 85, 1151, 8676],\n",
       " [3921, 3637],\n",
       " [2522, 10, 200, 8896, 13023],\n",
       " [441, 2973, 501, 339, 18118, 438, 6, 1043, 621, 26, 1251, 8022],\n",
       " [11794, 8466],\n",
       " [1, 507, 6, 2000, 7, 936, 1026, 4676],\n",
       " [57, 292, 528, 16, 152, 115, 4, 1, 47196, 12498],\n",
       " [16914, 5402, 2, 3516, 27, 234, 1656, 16, 1, 1222, 1053],\n",
       " [1, 71, 18, 1013, 367, 103],\n",
       " [1559, 1723, 6, 708, 86, 1141, 10127, 650],\n",
       " [18853, 5591, 15020],\n",
       " [20, 2000, 1267],\n",
       " [185, 1439, 12, 101, 12151],\n",
       " [65, 10, 76, 2469, 4, 34, 377],\n",
       " [1415, 3, 6249, 2974, 1311, 20, 15078, 912],\n",
       " [1, 365, 2, 155, 3, 207, 267, 10, 64407],\n",
       " [1, 10334, 774, 905, 10, 7297, 4, 1, 1930, 5348],\n",
       " [64, 14744, 232, 5384],\n",
       " [57, 6, 1223, 2086, 6281, 1122, 2156, 34, 558],\n",
       " [8689, 1479, 1613, 648, 284, 2005],\n",
       " [1, 4075, 54, 2294, 657, 2179, 2, 52, 63],\n",
       " [57, 6, 339, 4131],\n",
       " [7364, 951],\n",
       " [7751, 52],\n",
       " [1, 1509, 1271, 2, 1129, 20, 543, 725, 2314, 101, 2543, 309, 10439],\n",
       " [1477, 4819, 2341, 3503],\n",
       " [1222, 220, 20, 8865, 797, 2339, 830, 3, 273, 2521],\n",
       " [1, 1156, 2, 1, 7435, 149, 52724],\n",
       " [333, 222, 1415],\n",
       " [1, 3217, 5938, 2231],\n",
       " [43, 36695, 6278, 294, 15330, 39, 15287],\n",
       " [680, 3492, 12, 5, 2, 2164, 2612, 17543, 4, 1882],\n",
       " [1, 3140, 15579],\n",
       " [7, 1601, 6612, 10999, 15, 24750, 2840, 947, 4, 519],\n",
       " [1015, 275, 205, 16257, 947, 4, 5661, 2436],\n",
       " [2632, 9722],\n",
       " [1688, 3027, 3731, 3, 221, 779, 4310, 33, 450, 5250, 15, 286],\n",
       " [101, 4044, 6, 14832, 3815, 33, 9986, 63],\n",
       " [600, 6327, 16, 2825, 5181, 170, 12, 37867, 2459, 56, 19319, 3330],\n",
       " [1013, 10, 7, 10618, 11261],\n",
       " [7, 1464, 737, 6, 368, 308],\n",
       " [293, 9409, 9296, 7, 15321, 10730, 20, 1, 8243],\n",
       " [2417, 12498, 26, 1, 891, 43071, 4, 1181, 48428],\n",
       " [1623, 6522, 1170, 4647],\n",
       " [10891, 2, 7, 2271, 223, 993, 672],\n",
       " [359, 28321],\n",
       " [1545, 207, 267, 190],\n",
       " [64, 1295, 1, 492, 6, 232, 1284, 6, 1618, 7, 3170, 3, 41401, 596, 426],\n",
       " [209, 28, 10, 838, 6, 583, 56, 1317, 7, 1129, 10620],\n",
       " [359, 48, 4166, 85, 224, 5313, 101, 277, 7, 784, 7394],\n",
       " [10730, 33092, 33, 3368, 4, 421],\n",
       " [12833, 43, 207, 267, 8837],\n",
       " [1021, 12, 116, 4347],\n",
       " [21569, 6676, 4, 4140, 567],\n",
       " [1, 4973, 420],\n",
       " [1, 3295, 3073, 18, 941, 286],\n",
       " [57, 6, 173, 85, 529, 14881],\n",
       " [1089, 5138, 58, 4884],\n",
       " [9014, 3252],\n",
       " [26806, 17535, 15, 39958, 136, 1677, 1, 1340, 2, 1129],\n",
       " [70316, 903, 634, 144, 5085, 75, 6157, 6613, 1465, 2335, 20, 525],\n",
       " [5322, 57, 6, 115, 15, 1542],\n",
       " [1, 40534, 7410, 1176, 6, 37764],\n",
       " [1303, 398, 2, 1, 308, 25633],\n",
       " [333, 7, 1375, 4, 220, 6, 1685, 85, 1572, 607],\n",
       " [2183, 975, 31747, 4386, 148, 8298],\n",
       " [11357, 6, 506, 5008, 3299, 101, 723, 3, 49],\n",
       " [1, 1013, 17486],\n",
       " [30663, 4, 487],\n",
       " [8783, 64326, 13572, 9428, 382],\n",
       " [7, 13420, 397, 128, 4, 14036, 849, 2, 487],\n",
       " [69917, 345, 7, 9753, 20, 232, 6847, 337],\n",
       " [57, 5924, 20, 680, 3511, 210, 254, 996],\n",
       " [5744, 14927, 843, 1941, 13, 2032, 1190, 514, 2320, 23390],\n",
       " [169, 114, 6, 708, 86, 5390, 2, 207, 267],\n",
       " [2446, 91, 1932, 3215, 4264, 839, 5766, 3094],\n",
       " [29, 13085, 6241, 20, 8395, 681, 6, 1468, 7, 197, 2, 1074, 14480],\n",
       " [17928, 1820, 7, 43370, 995, 4, 6130, 15, 600],\n",
       " [4081, 1, 491, 8642, 3950, 1332, 61, 7, 1309, 75, 16322],\n",
       " [272, 2530],\n",
       " [27366, 4, 3012],\n",
       " [12040, 4351],\n",
       " [1, 802, 64, 78, 6, 506, 232, 538],\n",
       " [17229, 67117],\n",
       " [57, 6, 3110, 2529, 26, 4601, 975, 6, 62068],\n",
       " [5553, 791, 57, 6, 78, 10842, 8670],\n",
       " [2000, 7, 1960, 4, 7, 2082, 87],\n",
       " [4466, 2, 165],\n",
       " [190, 618, 906, 232, 113],\n",
       " [1013, 207, 18675, 2139],\n",
       " [129, 4816, 10439],\n",
       " [7, 238, 56, 437, 32, 177, 3743],\n",
       " [8399, 1186, 14108, 1320, 13, 45, 1186, 3959, 1079, 511],\n",
       " [767, 12979],\n",
       " [2303, 28, 125, 7, 1234],\n",
       " [13946, 643, 2445, 1328, 11414],\n",
       " [18682, 760, 10972, 1179, 3, 17950, 6754],\n",
       " [1, 43, 283, 264, 203, 917, 33, 7, 13691],\n",
       " [320, 7, 5411, 891, 4, 6003],\n",
       " [23459, 13, 1694, 14928],\n",
       " [64, 68245, 232, 15247, 2899, 15, 72, 11, 4000],\n",
       " [1780, 1932, 10, 1609, 6, 38184, 445, 13, 3989, 1865, 2873],\n",
       " [7, 1691, 12, 28109, 1197, 10, 4, 45, 599, 3979, 1445],\n",
       " [11967, 1426, 3503],\n",
       " [27349, 9403, 4615, 2, 22243],\n",
       " [7, 43, 728, 87, 136, 342, 1771],\n",
       " [9225, 6, 946, 3330, 6, 179, 1918, 4, 21, 421, 615],\n",
       " [57, 13666, 27, 101, 8226, 13, 6239, 12, 44, 254, 1151],\n",
       " [59164, 23642, 4422, 20, 7, 726, 3098],\n",
       " [49, 67, 5748, 501, 1954, 15, 7, 2679, 134, 115, 1215],\n",
       " [1, 365, 2, 382, 10, 1228],\n",
       " [209, 53360, 12404, 27, 100, 2371],\n",
       " [1217, 4570, 2, 7, 43, 2528, 672],\n",
       " [2685, 610, 2044],\n",
       " [74, 57, 59, 264, 97, 1021, 732, 22, 13175],\n",
       " [10641, 469, 3631, 1630, 3503],\n",
       " [2947, 223, 1542, 15, 7, 61926, 405, 2, 3637],\n",
       " [9324, 111, 377, 20, 1, 1559, 4, 324, 1729],\n",
       " [14865, 112, 2824, 271, 14736, 1260, 23085, 12, 5455],\n",
       " [807, 85, 1558, 61, 7, 4090, 13828],\n",
       " [3885, 1797, 6, 3076, 57, 838, 1, 5639, 10],\n",
       " [14832, 8, 34578, 560, 4, 34660, 1736],\n",
       " [3215, 9059, 301, 18679, 1637, 3544, 16858, 2328],\n",
       " [15469, 7159, 3722],\n",
       " [295, 582, 15, 8268, 3, 109, 1545, 48, 161, 6, 3067, 117],\n",
       " [663, 2692, 1312, 1108, 211, 1162, 30, 10169],\n",
       " [13647, 19191],\n",
       " [162, 39164, 40, 511],\n",
       " [1676, 750, 2303, 10169, 20, 7, 23415],\n",
       " [54602, 6042],\n",
       " [19950, 10, 1954, 190, 1520, 6, 23359, 722, 551],\n",
       " [7027, 86, 3993, 241, 26, 2351, 2301],\n",
       " [209, 684, 15797, 10, 7, 6837],\n",
       " [6060, 27, 101, 223, 1542, 12369, 6, 962, 55194, 4, 2872],\n",
       " [10813],\n",
       " [1, 522],\n",
       " [8143, 10983, 41199, 8619, 8587],\n",
       " [10745, 96, 648, 4, 4668],\n",
       " [57, 6, 2758, 26, 49, 67, 1477, 2541, 3, 339, 1230, 6, 40276, 3503],\n",
       " [12508, 6485, 3, 50, 1130, 6, 339, 97, 651],\n",
       " [870, 6812, 648, 1286, 12, 337, 327],\n",
       " [1, 5752, 1351, 84, 2925, 3, 246],\n",
       " [57, 6, 284, 167, 2231, 10308],\n",
       " [1524, 331, 1649, 27, 1623, 448, 13, 514, 3, 1465, 5823, 3466, 301, 1747],\n",
       " [2632, 26932, 678, 26967],\n",
       " [3431, 221],\n",
       " [209, 7, 3503, 7748, 77, 31, 1604, 111, 46],\n",
       " [66, 525, 2473, 232, 784],\n",
       " [421, 2393, 39, 2915, 7, 11682, 1839, 6, 20887, 2851, 4510],\n",
       " [295, 284, 1881, 6, 842, 12, 1, 223, 4533, 6345, 880],\n",
       " [503, 190, 512, 18, 27, 794, 172, 4095],\n",
       " [3503, 796, 765],\n",
       " [1155, 12, 3960, 1923, 2462],\n",
       " [1, 1017, 11738, 18, 449, 3809, 1312, 1485],\n",
       " [1011, 6, 8660, 5806, 26, 271, 22445],\n",
       " [3448, 1018, 166, 963, 12, 1141],\n",
       " [2038, 85, 323, 1317, 7, 284, 87],\n",
       " [1, 3504, 3720, 54210],\n",
       " [57, 6, 173, 29, 6493, 8790, 3647],\n",
       " [46709],\n",
       " [148, 775, 2574, 2510, 1703, 792, 4, 198, 286, 395],\n",
       " [158, 2, 4317, 661, 2994, 2401],\n",
       " [1514, 236, 27899, 20517, 12, 415, 2546, 134, 4, 7, 3682],\n",
       " [6693, 16281, 86, 211, 338],\n",
       " [1920, 28681, 6, 403, 25079],\n",
       " [4250, 225, 2890],\n",
       " [7, 1755, 12, 15242, 85, 586, 20, 397, 1213, 582],\n",
       " [1024, 2, 6238, 2515],\n",
       " [2153, 308, 4, 1, 1228, 3, 2327, 1869, 1250],\n",
       " [256, 2615, 32076, 6005, 301, 288, 58, 555, 7, 138, 2, 426],\n",
       " [57, 348, 1332, 144, 1, 47, 4537],\n",
       " [680, 2307, 696, 6, 525, 3544, 10581, 75, 90, 4, 2872],\n",
       " [2738, 6, 2606, 716, 36781, 2, 1, 822],\n",
       " [126, 36660, 469],\n",
       " [2392, 28897, 4, 1903, 40207],\n",
       " [406, 2987, 1465, 1294, 190, 1259],\n",
       " [545, 20, 29, 4783, 1181],\n",
       " [2045, 3605, 223, 10, 1937, 1185, 359, 802, 6, 693],\n",
       " [34, 460, 292, 1038],\n",
       " [3051, 69194, 26451, 13, 7531, 21548, 20, 1291, 313],\n",
       " [284, 10, 1, 369, 4744, 4, 709, 308],\n",
       " [2598, 8439],\n",
       " [282, 6, 1043, 2086, 426, 2318, 13, 468, 6575, 18875],\n",
       " [2846, 2537, 1317, 49, 2426, 12, 1013, 1618, 58, 1331, 7893, 5578, 42692],\n",
       " [169, 1453, 2455, 78, 359, 6, 3271, 23801, 44549, 13986],\n",
       " [1021, 12740, 1972, 6, 403, 2418, 565, 2, 222],\n",
       " [1734, 3460, 6, 803, 86, 269, 2, 7752, 195],\n",
       " [1322, 12, 246, 1365, 3, 4618],\n",
       " [4278, 9523, 1002, 5178, 4, 484, 6030, 1761, 3330],\n",
       " [39024, 64613],\n",
       " [96, 1884, 27, 24533, 68, 218, 3040],\n",
       " [223, 403, 40, 4499, 232, 855, 12, 778],\n",
       " [3791, 4, 35630],\n",
       " [1, 3775, 2743, 6, 16710],\n",
       " [208, 2372, 2207, 37597, 1382, 6, 3546, 6, 515, 724, 3343],\n",
       " [609, 2, 188, 15952, 3250, 26, 7, 302, 2165, 5976, 1306],\n",
       " [1423, 9850, 18297, 1846, 4988, 12, 3859],\n",
       " [7511, 13917, 8575],\n",
       " [1950, 1517],\n",
       " [1, 484, 3305, 35617, 10, 29, 13298, 1420, 8830],\n",
       " [1, 9453, 3574],\n",
       " [7594, 4462, 97, 2726, 1, 796, 87, 1047, 4, 487, 222],\n",
       " [8358, 487, 15, 8358],\n",
       " [1091, 3874, 292, 37, 11871],\n",
       " [463, 1148, 6067, 4311, 196, 6, 31, 4815, 15, 205, 931],\n",
       " [37757, 1554, 20, 1, 90, 4, 2872],\n",
       " [57, 6, 13657, 7, 39899, 1003, 6, 2453, 1668, 124, 6741],\n",
       " [4738, 2, 222, 3503],\n",
       " [30304],\n",
       " [8458, 3, 22169, 85, 180, 124, 8358, 15, 34, 3142, 2231],\n",
       " [1, 2331, 2, 1, 168, 1234],\n",
       " [99, 2, 11402],\n",
       " [3578, 868, 484, 428, 9348, 994],\n",
       " [7, 503, 362, 6, 9324, 19561, 461, 61, 186, 2941],\n",
       " [18495, 411, 2104, 3503],\n",
       " [333, 948, 230, 151, 450],\n",
       " [1944, 20, 1, 1733, 1592],\n",
       " [49, 30, 299, 16466, 512, 97, 48, 161, 6, 1547, 487, 586],\n",
       " [556, 4, 1, 7052],\n",
       " [207, 1311, 4592, 33, 10457, 3064],\n",
       " [6506, 4, 7, 4180, 419],\n",
       " [1, 978, 31790, 1211],\n",
       " [232, 23770, 7461, 3844],\n",
       " [148, 96, 644, 3, 11019, 13, 4005, 7034],\n",
       " [1, 5662, 15328, 514, 333, 2852],\n",
       " [5160, 919],\n",
       " [20808, 2, 931, 2403, 48, 1677, 784, 1828, 58, 7, 5124],\n",
       " [57, 40166, 2921, 85, 17938],\n",
       " [20852, 1176, 21238, 239, 6, 3242, 58, 82, 20, 3159, 287, 995],\n",
       " [1, 24146, 3709, 83, 22968, 1, 338, 12, 82],\n",
       " [1, 11588, 227, 17954, 10, 18521, 13, 3394, 3, 11412, 2642, 86],\n",
       " [1019, 13, 222, 20, 70240, 411],\n",
       " [2679, 791, 6, 1103, 15, 38236, 80],\n",
       " [78, 85, 316, 4829, 384, 6, 173, 85, 1217, 384, 2534],\n",
       " [5190, 472, 4114, 15, 12517, 3, 1, 512, 399],\n",
       " [2827, 13764, 17624],\n",
       " [8823, 649, 2, 1, 47261, 5017, 1174, 26, 4425, 49657],\n",
       " [4246, 7363, 810, 36, 83, 803, 695, 54, 2, 32, 5465],\n",
       " [64, 17860, 7320, 61, 543, 94, 1736, 264, 553, 1215],\n",
       " [26845, 1, 27607, 3, 1, 4877, 935, 46818, 4, 11710],\n",
       " [28174],\n",
       " [7511, 3968, 20961],\n",
       " [9250, 3, 11080, 2, 104, 7, 7609, 1536],\n",
       " [2195, 7146, 26, 1606, 211, 1408, 29, 1304],\n",
       " [209, 3976, 545, 1317, 7, 3685, 1421, 332, 4, 129],\n",
       " [52, 97, 23099],\n",
       " [109, 143, 1407, 26, 7, 188, 14846],\n",
       " [7733, 2228, 3, 1770, 15, 1770, 796, 2228],\n",
       " [1, 4170, 4, 1, 2310, 18, 3725, 7861, 4, 63],\n",
       " [46818, 3, 1662],\n",
       " [209, 9146, 27, 37, 1526, 12, 12603],\n",
       " [6359, 971, 7, 237, 473, 15, 1, 47, 126, 2, 3242, 3681],\n",
       " [6319, 638, 247, 456, 1506, 48, 31, 5582],\n",
       " [1035, 273, 1053, 6, 1420, 214, 3, 2064, 4520, 2, 15903],\n",
       " [5757, 2, 1015, 15860, 4, 10297],\n",
       " [2000, 85, 4012],\n",
       " [7830, 2029, 4262, 1424, 114, 31089, 862, 3458],\n",
       " [943, 4472, 1029, 11634, 282, 12, 2283, 63],\n",
       " [13977, 86, 1, 609],\n",
       " [320, 7, 5330, 9271, 5356],\n",
       " [155, 190, 6575, 13, 7, 518, 2, 247, 4669],\n",
       " [57, 6, 875, 7, 495, 83],\n",
       " ...]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'what': [[ 0.44074917 -0.30176494 -0.41607687 -0.0878012   0.43704394 -0.6724253\n",
      "   0.5014559  -0.92947763 -0.39647016  1.2727047  -0.09769747 -0.06923263\n",
      "  -0.45475698  0.1573996  -0.15758702 -0.02607112 -0.40148208 -0.03070599\n",
      "   0.1965615   0.5524046   0.8085856   0.26795807  0.27516386 -0.22690798\n",
      "  -0.2845888   0.31643218  0.28090933 -0.22459322 -0.55772686  0.5850801\n",
      "  -0.83067137  0.15475136 -0.6453265  -0.6860369   1.0594829  -0.23154312\n",
      "   0.6355532   0.7737264   0.32928082  0.96605283  1.2200508   0.7165248\n",
      "   0.11037972  0.04014343  0.10452028 -0.87080467  0.49196586  0.64406115\n",
      "  -1.1156307   0.29073134  0.20857936  0.9940306   0.09512924 -0.37266222\n",
      "  -0.24315526  0.20552295  0.00417871  0.01204656  0.07589839  0.9898188\n",
      "   0.5909693  -0.6115431   0.40819883  0.4679865 ]]\n"
     ]
    }
   ],
   "source": [
    "# Function to get the embedding of a specific word\n",
    "def get_word_embedding(word, vocab, model):\n",
    "    # Check if the word is in the vocabulary\n",
    "    if word in reverse_vocab:\n",
    "        index = reverse_vocab[word]  # Get the index of the word\n",
    "        embedding = model.emb(torch.LongTensor([index]).to(device))  # Get the embedding for the word\n",
    "        return embedding.detach().cpu().numpy()  # Detach and convert to NumPy array\n",
    "    else:\n",
    "        print(f\"'{word}' not found in the vocabulary.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "word_to_inspect = \"what\"  # Replace with the word you want to inspect\n",
    "embedding_vector = get_word_embedding(word_to_inspect, updated_vocab, mFoo)\n",
    "\n",
    "if embedding_vector is not None:\n",
    "    print(f\"Embedding for '{word_to_inspect}': {embedding_vector}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAIjCAYAAABcTsmJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8xUlEQVR4nO3de3zP9f//8ft7ww7YMJuNxg6EmZzJeUJDkQ5GiCnknPDJobB1sESlnKI0hJJzCjmEcgotIuecag4zs83ZbK/fH757/7xt2NjMXm7Xy2WXej1fz/fz9Xi9n5S75+tgMQzDEAAAAADAtOxyugAAAAAAQPYi+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AHAQ2LdunWyWCxat25dTpdi5ePjo2effTbbj3P06FFZLBZNnz79rn1DQ0Pl4+Nj02axWBQWFpYttT1I06dPl8Vi0dGjRx+6OoKCghQUFPTAa8mp4wKA2RD8ADxSvv/+e1ksFi1atCjNvkqVKslisWjt2rVp9pUsWVJ16tR5ECXeVeofym/3s2XLlpwuEf+nVatWcnZ21vnz52/bp0OHDsqXL5/Onj37ACt7uOzZs0dhYWE5HngBwMzy5HQBAPAg1atXT5K0YcMGPf/889b2xMRE7d69W3ny5NHGjRvVqFEj675///1X//77r9q1a/fA672Td999V76+vmnaS5cunQPV5KzLly8rT56H739pHTp00NKlS7Vo0SJ16tQpzf5Lly5pyZIlatasmdzc3PTKK6+oXbt2cnBwyIFq72zlypXZNvaePXsUHh6uoKCgNKu52XlcAHiUPHz/lwSAbFS8eHH5+vpqw4YNNu2bN2+WYRhq06ZNmn2p26mh8V4ZhqErV67IycnpvsZJ1bx5c1WvXj1LxsrtHB0dc7qEdLVq1UoFCxbUnDlz0g1+S5Ys0cWLF9WhQwdJkr29vezt7R90mRmSL1++R+q4AGA2XOoJ4JFTr149/fnnn7p8+bK1bePGjapQoYKaN2+uLVu2KCUlxWafxWJR3bp1JUnXr1/Xe++9J39/fzk4OMjHx0fDhg3T1atXbY6Ten/czz//rOrVq8vJyUlTpkyRJP33339q3bq18ufPLw8PD7355ptpPn+/Uu+bGzt2rCZOnCg/Pz85Ozvr6aef1r///ivDMPTee+/psccek5OTk5577jnFxcWlO9bKlStVuXJlOTo6KiAgQAsXLkzTJz4+Xv3795e3t7ccHBxUunRpjR492ua7TO0XGhoqV1dXFSpUSJ07d1Z8fHy6x128eLECAwPl6OiowMDAdC/RldLe4xcWFiaLxaJDhw4pNDRUhQoVkqurq7p06aJLly7ZfPby5cvq16+fihYtqoIFC6pVq1aKjo5OM+b58+fVv39/+fj4yMHBQR4eHmratKmioqLSrUmSnJyc9MILL2jNmjWKiYlJs3/OnDnWY0rp31u3fft2BQcHq2jRonJycpKvr69effVV6/7b3Rua3n2Tf/31l0JDQ+Xn5ydHR0d5enrq1VdfzdBlprfea+fj43Pby41Tazl27Jh69eqlsmXLysnJSW5ubmrTpo3N+U2fPl1t2rSRJDVq1CjNGOnd4xcTE6PXXntNxYoVk6OjoypVqqQZM2ake/5jx47V1KlTrb9fa9SooW3btt31fAHAbFjxA/DIqVevnr755hv9/vvv1j9Qbty4UXXq1FGdOnWUkJCg3bt364knnrDuK1eunNzc3CRJXbt21YwZM/TSSy9p4MCB+v333xUREaG9e/emCSb79+/Xyy+/rNdff13dunVT2bJldfnyZTVu3FjHjx9Xv379VLx4cX3zzTf65ZdfMnUeCQkJio2NtWmzWCzWOlPNnj1b165dU9++fRUXF6ePPvpIISEheuqpp7Ru3ToNHjxYhw4d0vjx4zVo0CB9/fXXNp8/ePCg2rZtqx49eqhz586KjIxUmzZttGLFCjVt2lTSjUsWGzZsqOjoaL3++usqWbKkNm3apKFDh+rkyZMaN26cpBurns8995w2bNigHj16qHz58lq0aJE6d+6c5vxWrlypF198UQEBAYqIiNDZs2fVpUsXPfbYYxn+jkJCQuTr66uIiAhFRUXpq6++koeHh0aPHm3tExoaqu+//16vvPKKnnzySa1fv17PPPNMmrF69Oih+fPnq0+fPgoICNDZs2e1YcMG7d27V1WrVr1tDR06dNCMGTP0/fffq0+fPtb2uLg4/fzzz3r55ZdvuwocExOjp59+Wu7u7hoyZIgKFSqko0ePphu8M2LVqlU6fPiwunTpIk9PT/3999+aOnWq/v77b23ZskUWiyXDY40bN04XLlywafv000+1Y8cO66/Bbdu2adOmTWrXrp0ee+wxHT16VJMnT1ZQUJD27NkjZ2dnNWjQQP369dPnn3+uYcOGqXz58pJk/eetLl++rKCgIB06dEh9+vSRr6+v5s2bp9DQUMXHx+uNN96w6T9nzhydP39er7/+uiwWiz766CO98MILOnz4sPLmzZuZrw8AcjcDAB4xf//9tyHJeO+99wzDMIykpCQjf/78xowZMwzDMIxixYoZEydONAzDMBITEw17e3ujW7duhmEYxo4dOwxJRteuXW3GHDRokCHJ+OWXX6xtpUqVMiQZK1assOk7btw4Q5Lx/fffW9suXrxolC5d2pBkrF279o71R0ZGGpLS/XFwcLD2O3LkiCHJcHd3N+Lj463tQ4cONSQZlSpVMpKSkqztL7/8spEvXz7jypUrac5hwYIF1raEhATDy8vLqFKlirXtvffeM/Lnz28cOHDAptYhQ4YY9vb2xvHjxw3DMIzFixcbkoyPPvrI2uf69etG/fr1DUlGZGSktb1y5cqGl5eXTe0rV640JBmlSpWyOY4kY+TIkdbtkSNHGpKMV1991abf888/b7i5uVm3//jjD0OS0b9/f5t+oaGhacZ0dXU1evfubWTW9evXDS8vL6N27do27V988YUhyfj555+tbalze+TIEcMwDGPRokWGJGPbtm23HX/t2rXp/rpJnf+bv9NLly6l+fy3335rSDJ+/fXX29ZhGIbRsGFDo2HDhret4/vvvzckGe++++4dj7d582ZDkjFz5kxr27x58277a//W46b+/pk1a5a17dq1a0bt2rWNAgUKGImJiTbn7+bmZsTFxVn7LlmyxJBkLF269LbnAgBmxKWeAB455cuXl5ubm/XevZ07d+rixYvWp3bWqVNHGzdulHTj3r/k5GTr/X3Lli2TJA0YMMBmzIEDB0qSfvrpJ5t2X19fBQcH27QtW7ZMXl5eeumll6xtzs7O6t69e6bOY+LEiVq1apXNz/Lly9P0a9OmjVxdXa3btWrVkiR17NjR5oEotWrV0rVr1xQdHW3z+eLFi9s8CMfFxUWdOnXSn3/+qVOnTkmS5s2bp/r166tw4cKKjY21/jRp0kTJycn69ddfreeeJ08e9ezZ0zqevb29+vbta3PMkydPaseOHercubNN7U2bNlVAQECGv6MePXrYbNevX19nz55VYmKiJGnFihWSpF69etn0u7UeSSpUqJB+//13nThxIsPHl26cX7t27bR582abSxznzJmjYsWKqXHjxrf9bKFChSRJP/74o5KSkjJ13PTcvLJ45coVxcbG6sknn5SkO16yejd79uzRq6++queee07vvPNOusdLSkrS2bNnVbp0aRUqVOiej7ds2TJ5enrq5ZdftrblzZtX/fr104ULF7R+/Xqb/m3btlXhwoWt2/Xr15ckHT58+J6ODwC5FcEPwCPHYrGoTp061nv5Nm7cKA8PD+vTMG8Ofqn/TA1+x44dk52dXZonZ3p6eqpQoUI6duyYTXt6T908duyYSpcuneayurJly2bqPGrWrKkmTZrY/Nz8NNJUJUuWtNlODVLe3t7ptp87d86mPb1aH3/8cUmyBpmDBw9qxYoVcnd3t/lp0qSJJFnvbzt27Ji8vLxUoEABm/FuPffU77FMmTJpzicz39Ot554aAFLPMXU+b52n9J6M+tFHH2n37t3y9vZWzZo1FRYWluHwkPrwljlz5ki6cY/nb7/9pnbt2t3xYS4NGzbUiy++qPDwcBUtWlTPPfecIiMj7/l+0Li4OL3xxhsqVqyYnJyc5O7ubj33hISEexozMTFRL7zwgkqUKKGZM2fa/Fq5fPmyRowYYb3vs2jRonJ3d1d8fPw9H+/YsWMqU6aM7Oxs/wiTemnorb8H7/ZrAAAeFQQ/AI+kevXqKSEhQbt27bLe35eqTp06OnbsmKKjo7VhwwYVL15cfn5+Np/P6L1QWfUEz/txu2Bxu3bDMDJ9jJSUFDVt2jTNCmTqz4svvpjpMbNCVp5jSEiIDh8+rPHjx6t48eIaM2aMKlSokO4q662qVaumcuXK6dtvv5UkffvttzIMwxoIb8disWj+/PnavHmz+vTpo+joaL366quqVq2a9f662/1aTE5OTvccvvzyS/Xo0UMLFy7UypUrrauetz6EJ6NCQ0N14sQJLV68WC4uLjb7+vbtqw8++EAhISH6/vvvtXLlSq1atUpubm73fLzMyspfAwCQm/FwFwCPpJvf57dx40b179/fuq9atWpycHDQunXr9Pvvv6tFixbWfaVKlVJKSooOHjxo8/CJ06dPKz4+XqVKlbrrsUuVKqXdu3fLMAybP7Tv378/C84s6x06dChNrQcOHJAk6zvX/P39deHCBesK3+2UKlVKa9as0YULF2xW/W4999Tv8eDBg2nGyMrvKXU+jxw5YrO6eOjQoXT7e3l5qVevXurVq5diYmJUtWpVffDBB2revPldj9WhQwcNHz5cf/31l+bMmaMyZcqoRo0aGarzySef1JNPPqkPPvhAc+bMUYcOHfTdd9+pa9eu1hWsW5+MeuvK17lz57RmzRqFh4drxIgR1vb0vuOM+vDDD7V48WItXLhQ5cqVS7N//vz56ty5sz7++GNr25UrV9LUmpmHypQqVUp//fWXUlJSbFb99u3bZ90PAEiLFT8Aj6Tq1avL0dFRs2fPVnR0tM2Kn4ODg6pWraqJEyfq4sWLNu/vSw2BqU+pTPXJJ59IUrpPg7xVixYtdOLECc2fP9/adunSJU2dOvV+TinbnDhxwuZppYmJiZo5c6YqV64sT09PSTdWkjZv3qyff/45zefj4+N1/fp1STfO/fr165o8ebJ1f3JyssaPH2/zGS8vL1WuXFkzZsywuSRw1apV2rNnT5adW+r9l5MmTbJpv7We5OTkNJcmenh4qHjx4hm+7DJ1dW/EiBHasWPHXVf7pBth7daVqcqVK0uS9bilSpWSvb299T7KVLeeU+rK163j3fprOaNWr16td955R2+//bZat26dbh97e/s0xxs/fnya1cj8+fNLShte09OiRQudOnVKc+fOtbZdv35d48ePV4ECBdSwYcPMnQgAPCJY8QPwSMqXL59q1Kih3377TQ4ODqpWrZrN/jp16lhXKW4OfpUqVVLnzp01depUxcfHq2HDhtq6datmzJih1q1bp3uP3a26deumCRMmqFOnTvrjjz/k5eWlb775Rs7Ozpk6h+XLl1tXOW6t/dZLU+/H448/rtdee03btm1TsWLF9PXXX+v06dOKjIy09vnf//6nH374Qc8++6xCQ0NVrVo1Xbx4Ubt27dL8+fN19OhRFS1aVC1btlTdunU1ZMgQHT161PpOwPTu94qIiNAzzzyjevXq6dVXX1VcXJzGjx+vChUqpHmNwL2qVq2aXnzxRY0bN05nz561vs4hdUUzdSXq/Pnzeuyxx/TSSy+pUqVKKlCggFavXq1t27bZrGbdia+vr+rUqaMlS5ZIUoaC34wZMzRp0iQ9//zz8vf31/nz5/Xll1/KxcXF+pcQrq6uatOmjcaPHy+LxSJ/f3/9+OOPad4b6OLiogYNGuijjz5SUlKSSpQooZUrV+rIkSMZ/r5u9vLLL8vd3V1lypTRrFmzbPY1bdpUxYoV07PPPqtvvvlGrq6uCggI0ObNm7V69eo0rxypXLmy7O3tNXr0aCUkJMjBwUFPPfWUPDw80hy3e/fumjJlikJDQ/XHH3/Ix8dH8+fP18aNGzVu3DgVLFjwns4HAMyO4AfgkVWvXj399ttv1ks7b1a3bl19/PHHKliwoCpVqmSz76uvvpKfn5+mT5+uRYsWydPTU0OHDtXIkSMzdFxnZ2etWbNGffv21fjx4+Xs7KwOHTqoefPmatasWYbrv/lyvZtFRkZmafArU6aMxo8fr//973/av3+/fH19NXfuXJunlTo7O2v9+vUaNWqU5s2bp5kzZ8rFxUWPP/64wsPDrQ+OsbOz0w8//KD+/ftr1qxZslgsatWqlT7++GNVqVLF5rjNmjXTvHnz9M4772jo0KHy9/dXZGSklixZkuZl5fdj5syZ8vT01LfffqtFixapSZMmmjt3rsqWLStHR0fr+fXq1UsrV67UwoULlZKSotKlS2vSpEk2Tyi9mw4dOmjTpk2qWbNmug+QuVXqXyx89913On36tFxdXVWzZk3Nnj3b5oE048ePV1JSkr744gs5ODgoJCREY8aMUWBgoM14c+bMUd++fTVx4kQZhqGnn35ay5cvV/HixTN8DqlS3yGZ3jsY165dq2LFiumzzz6Tvb29Zs+erStXrqhu3bpavXp1mifdenp66osvvlBERIRee+01JScna+3atekGPycnJ61bt05DhgzRjBkzlJiYqLJlyyoyMlKhoaGZPg8AeFRYDO5uBgDAxo4dO1SlShXNmjUrQytzAAA87LjHDwDwSLt8+XKatnHjxsnOzk4NGjTIgYoAAMh6XOoJAHikffTRR/rjjz/UqFEj5cmTR8uXL9fy5cvVvXv3NO86BAAgt+JSTwDAI23VqlUKDw/Xnj17dOHCBZUsWVKvvPKK3n77beXJw9+PAgDMgeAHAAAAACbHPX4AAAAAYHIEPwAAAAAwuUfq5oWUlBSdOHFCBQsWtL6UFwAAAMCjxzAMnT9/XsWLF5ednfnXwx6p4HfixAme0AYAAADA6t9//9Vjjz2W02Vku0cq+BUsWFDSjcl1cXHJ0rGTkpK0cuVKPf3008qbN2+Wjo2cw7yaD3NqPsyp+TCn5sS8mk9un9PExER5e3tbM4LZPVLBL/XyThcXl2wJfs7OznJxccmVv/CRPubVfJhT82FOzYc5NSfm1XzMMqePyi1g5r+YFQAAAAAecQQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHPMSmT58ui8Wi7du3Z/uxgoKCFBQUlO3HAQAAwINH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfkAOOHbsmHr16qWyZcvKyclJbm5uatOmjY4ePZpu/0uXLun111+Xm5ubXFxc1KlTJ507dy5Nv0mTJqlChQpycHBQ8eLF1bt3b8XHx6fpN3XqVPn7+8vJyUk1a9bUb7/9lu5xr169qpEjR6p06dJycHCQt7e33nrrLV29evV+Th8AAAAPWJ6cLgB4FG3btk2bNm1Su3bt9Nhjj+no0aOaPHmygoKCtGfPHjk7O9v079OnjwoVKqSwsDDt379fkydP1rFjx7Ru3TpZLBZJUlhYmMLDw9WkSRP17NnT2m/btm3auHGj8ubNK0maNm2aXn/9ddWpU0f9+/fX4cOH1apVKxUpUkTe3t7WY6akpKhVq1basGGDunfvrvLly2vXrl369NNPdeDAAS1evPiBfV8AAAC4PwQ/IAc888wzeumll2zaWrZsqdq1a2vBggV65ZVXbPbly5dPa9assYa3UqVK6a233tLSpUvVqlUrnTlzRhEREXr66ae1fPly2dndWMwvV66c+vTpo1mzZqlLly5KSkrSsGHDVLlyZa1du1b58uWTJAUEBKh79+42wW/OnDlavXq11q9fr3r16lnbAwMD1aNHD23atEl16tTJlu8HAAAAWYtLPYEc4OTkZP33pKQknT17VqVLl1ahQoUUFRWVpn/37t2toU+SevbsqTx58mjZsmWSpNWrV+vatWvq37+/NfRJUrdu3eTi4qKffvpJkrR9+3bFxMSoR48e1tAnSaGhoXJ1dbU55rx581S+fHmVK1dOsbGx1p+nnnpKkrR27dos+CYAAADwILDiB+SAy5cvKyIiQpGRkYqOjpZhGNZ9CQkJafqXKVPGZrtAgQLy8vKy3hN47NgxSVLZsmVt+uXLl09+fn7W/an/vHW8vHnzys/Pz6bt4MGD2rt3r9zd3dM9h5iYmLudJgAAAB4SBD/gAUlOMbT1SJxizl/RtFGD9dOCb9W/f3/Vrl1brq6uslgsateunVJSUnK6VEk37vGrWLGiPvnkk3T333xZKAAAAB5uBD/gAVix+6TCl+7RyYQrkqTjPyxW0SpN1bTLIDUL9JIkXblyJd0ncEo3Vt8aNWpk3b5w4YJOnjypFi1aSLpxz58k7d+/32bl7tq1azpy5IiaNGli0+/gwYPWSzalG5ebHjlyRJUqVbK2+fv7a+fOnWrcuLH1ATIAAADInXLVPX7R0dHq2LGj3Nzc5OTkpIoVK2r79u05XRZwRyt2n1TPWVHW0CdJFoudLl9NVs9ZUVqx+6Qkafz48UpOTk53jKlTpyopKcm6PXnyZF2/fl3NmzeXJDVp0kT58uXT559/bnPZ6LRp05SQkKBnnnlGklS9enW5u7vriy++0LVr16z9pk+fniZ0hoSEKDo6Wl9++WWaei5fvqyLFy9m8psAAABATsk1K37nzp1T3bp11ahRIy1fvlzu7u46ePCgChcunNOlAbeVnGIofOkeGbe0O5WuoQt//yKLg7N67fdTA9d4rVmzWm5ubumOc+3aNTVu3FghISHav3+/Jk2apHr16qlVq1aSJHd3dw0dOlTh4eFq1qyZWrVqZe1Xo0YNdezYUdKNe/nef/99vf7663rqqafUtm1bHTlyRJGRkWnu8XvllVf0/fffq0ePHlq7dq3q1q2r5ORk7du3T99//71+/vlnVa9ePcu/MwAAAGS9XBP8Ro8eLW9vb0VGRlrbfH19c7Ai4O62HomzWelLVaRxd8lip4t71unCrlXyqFVbq1evVnBwcLrjTJgwQbNnz9aIESOUlJSkl19+WZ9//rnNJZhhYWFyd3fXhAkT9Oabb6pIkSLq3r27Ro0aZfNE0O7duys5OVljxozR//73P1WsWFE//PCDhg8fbnNMOzs7LV68WJ9++qlmzpypRYsWydnZWX5+fnrjjTf0+OOPZ9G3BAAAgOxmMW6+LuwhFhAQoODgYP33339av369SpQooV69eqlbt263/czVq1d19epV63ZiYqK8vb0VGxsrFxeXLK0vKSlJq1atUtOmTW3+kI3c7X7nddmuk3prwV937ffRi0+oRUWveykRmcTvVfNhTs2HOTUn5tV8cvucJiYmqmjRokpISMjybPAwyjXBz9HRUZI0YMAAtWnTRtu2bdMbb7yhL774Qp07d073M2FhYQoPD0/TPmfOHDk7O2drvQAAAAAeXpcuXVL79u0Jfg+bfPnyqXr16tq0aZO1rV+/ftq2bZs2b96c7mdY8cP9ut95TU4xFDzuV51OvJLmPj9Jskgq5uKon/s3kL0dT858EPi9aj7Mqfkwp+bEvJpPbp/TR23FL9fc4+fl5aWAgACbtvLly2vBggW3/YyDg4McHBzStOfNmzfbfnFm59jIOfc6r3klDX2mgnrOipIkm/CXGvOGPlNBjg757rtGZA6/V82HOTUf5tScmFfzya1zmhtrvh+55nUOdevW1f79+23aDhw4YH0vGfCwahbopckdq8rT1dGm3dPVUZM7VrW+xw8AAADILrlmxe/NN99UnTp1NGrUKIWEhGjr1q2aOnWqpk6dmtOlAXfVLNBLTQM8tfVInGLOX5FHQUfV9C3C5Z0AAAB4IHJN8KtRo4YWLVqkoUOH6t1335Wvr6/GjRunDh065HRpQIbY21lU2z/99/QBAAAA2SnXBD9JevbZZ/Xss8/mdBkAAAAAkKvkmnv8AAAAAAD3huAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACaXa4Pfhx9+KIvFov79++d0KQAAAADwUMuVwW/btm2aMmWKnnjiiZwuBQAAAAAeerku+F24cEEdOnTQl19+qcKFC+d0OQAAAADw0MuT0wVkVu/evfXMM8+oSZMmev/99+/Y9+rVq7p69ap1OzExUZKUlJSkpKSkLK0rdbysHhc5i3k1H+bUfJhT82FOzYl5NZ/cPqe5te57ZTEMw8jpIjLqu+++0wcffKBt27bJ0dFRQUFBqly5ssaNG5du/7CwMIWHh6dpnzNnjpydnbO5WgAAAAAPq0uXLql9+/ZKSEiQi4tLTpeT7XJN8Pv3339VvXp1rVq1ynpv392CX3orft7e3oqNjc3yyU1KStKqVavUtGlT5c2bN0vHRs5hXs2HOTUf5tR8mFNzYl7NJ7fPaWJioooWLfrIBL9cc6nnH3/8oZiYGFWtWtXalpycrF9//VUTJkzQ1atXZW9vb/MZBwcHOTg4pBkrb9682faLMzvHRs5hXs2HOTUf5tR8mFNzYl7NJ7fOaW6s+X7kmuDXuHFj7dq1y6atS5cuKleunAYPHpwm9AEAAAAAbsg1T/UsWLCgAgMDbX7y588vNzc3BQYG5nR5AB4yYWFhslgsio2NzelSAAAAclyuCX4AAAAAgHuTay71TM+6detyugQAAAAAeOix4gcAAAAAJkfwA2Bq8fHxCg0NVaFCheTq6qquXbvavObl+vXreu+99+Tv7y8HBwf5+Pho2LBhNn0kyWKxKCwsLM34Pj4+Cg0NtW4nJSUpPDxcZcqUkaOjo9zc3FSvXj2tWrXK5nP79u3TSy+9pCJFisjR0VHVq1fXDz/8kKXnDgAAkIrgB8DUQkJCdP78eUVERCgkJEQzZ87Ud999Z93ftWtXjRgxQlWrVtWnn36qhg0bKiIiQu3atbun44WFhSk8PFyNGjXShAkT9Pbbb6tkyZKKioqy9vn777/15JNPau/evRoyZIg+/vhj5c+fX61bt9aiRYvu+5wBAABulavv8QOAu6lSpYqmTZtm3T5z5oxWr14tSdq5c6dmzJihrl276ssvv5Qk9erVSx4eHho7dqzWrl2rRo0aZep4P/30k1q0aKGpU6fets8bb7yhkiVLatu2bdZ3jfbq1Uv16tXT4MGD9fzzz2f2NAEAAO6IFT8AptajRw+b7Xr16un8+fNKTEzUsmXLJEkDBgyw6TNw4EBJN0JcZhUqVEh///23Dh48mO7+uLg4/fLLL9aVyNjYWMXGxurs2bMKDg7WwYMHFR0dnenjAgAA3AnBD4BpJKcY2vzPWS3ZEa1/4y5JkkqWLGnTp3DhwpKkc+fO6dixY7Kzs1Pp0qVt+nh6eqpQoUI6duxYpmt49913FR8fr8cff1wVK1bU//73P/3111/W/YcOHZJhGBo+fLjc3d1tfkaOHClJiomJyfRxAQAA7oRLPQGYwordJxW+dI9OJlyRJMVH/SdJWnfgjNoWK5amv2EY1n+3WCz3fNzk5GSb7QYNGuiff/7RkiVLtHLlSn311Vf69NNP9cUXX6hr165KSUmRJA0aNEjBwcHpjnlrEAUAALhfBD8Aud6K3SfVc1aUjHT2/W/eX3It7KZmgV5p9pUqVUopKSk6ePCgypcvb20/ffq04uPjVapUKWtb4cKFFR8fb/P5a9eu6eTJk2nGLVKkiLp06aIuXbrowoULatCggcLCwtS1a1f5+flJkvLmzasmTZrc2wkDAABkEpd6AsjVklMMhS/dk27oSxW+dI+SU9L2aNGihSRp3LhxNu2ffPKJJOmZZ56xtvn7++vXX3+16Td16tQ0K35nz5612S5QoIBKly5tfT2Eh4eHgoKCNGXKlHRD45kzZ+5wJgAAAPeGFT8AudrWI3HWyzvTY0g6mXBFW4/Eqba/m82+SpUqqXPnzpo6dari4+PVsGFDbd26VTNmzFDr1q1tnujZtWtX9ejRQy+++KKaNm2qnTt36ueff1bRokVtxgwICFBQUJCqVaumIkWKaPv27Zo/f7769Olj7TNx4kTVq1dPFStWVLdu3eTn56fTp09r8+bN+u+//7Rz586s+XIAAAD+D8EPQK4Wc/72oS8j/b766iv5+flp+vTpWrRokTw9PTV06FDrg1ZSdevWTUeOHNG0adO0YsUK1a9fX6tWrVLjxo1t+vXr108//PCDVq5cqatXr6pUqVJ6//339b///c/aJyAgQNu3b1d4eLimT5+us2fPysPDQ1WqVNGIESMy+Q0AAADcHcEPQK7mUdAx3fZC9TqoUL0Oafp16tRJRYsWlY+PjyQpT548GjFixF0Dl52dnT788EN9+OGHNu1Hjx612X777bf19ttv37VuPz8/zZgx4679AAAAsgL3+AHI1Wr6FpGXq6Nu91xOiyQvV0fV9C3yIMsCAAB4qBD8AORq9nYWjWwZIElpwl/q9siWAbK3u/dXNgAAAOR2BD8AuV6zQC9N7lhVnq62l316ujpqcseq6b7KAQAA4FHCPX4ATKFZoJeaBnhq65E4xZy/Io+CNy7vZKUPAACA4AfAROztLGle2QAAAAAu9QQAAAAA0yP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMLlPB7/Lly9qwYYP27NmTZt+VK1c0c+bMLCsMAAAAAJA1Mhz8Dhw4oPLly6tBgwaqWLGiGjZsqJMnT1r3JyQkqEuXLtlSJAAAAADg3mU4+A0ePFiBgYGKiYnR/v37VbBgQdWtW1fHjx/PzvoAAAAAAPcpw8Fv06ZNioiIUNGiRVW6dGktXbpUwcHBql+/vg4fPpydNUqSIiIiVKNGDRUsWFAeHh5q3bq19u/fn+3HBQAAAIDcLsPB7/Lly8qTJ49122KxaPLkyWrZsqUaNmyoAwcOZEuBqdavX6/evXtry5YtWrVqlZKSkvT000/r4sWL2XpcAAAAAMjt8ty9yw3lypXT9u3bVb58eZv2CRMmSJJatWqVtZXdYsWKFTbb06dPl4eHh/744w81aNAg3c9cvXpVV69etW4nJiZKkpKSkpSUlJSl9aWOl9XjImcxr+bDnJoPc2o+zKk5Ma/mk9vnNLfWfa8shmEYGekYERGh3377TcuWLUt3f69evfTFF18oJSUlSwu8nUOHDqlMmTLatWuXAgMD0+0TFham8PDwNO1z5syRs7NzdpcIwES+/fZbzZ07VzNnzpSLi0tOlwMAAO7TpUuX1L59eyUkJDwS/2/PcPB7mKSkpKhVq1aKj4/Xhg0bbtsvvRU/b29vxcbGZvnkJiUladWqVWratKny5s2bpWMj5zCv5nOvc/ruu+/q/fff14kTJ1S0aNFsrBCZxe9T82FOzYl5NZ/cPqeJiYkqWrToIxP8Mnyp58Okd+/e2r179x1DnyQ5ODjIwcEhTXvevHmz7Rdndo6NnMO8mk9m59Te3v6ePocHh7kxH+bUnJhX88mtc5oba74fuS749enTRz/++KN+/fVXPfbYYzldDgAAAAA89DL8VM+cZhiG+vTpo0WLFumXX36Rr69vTpcE4BEUHx+v0NBQFSpUSK6ururSpYsuXbpk3X/9+nW999578vf3l4ODg3x8fDRs2DCby84lycfHR88++6zWrVun6tWry8nJSRUrVtS6deskSQsXLlTFihXl6OioatWq6c8//0xTy759+/TSSy+pSJEicnR0VPXq1fXDDz9k6/kDAIDcKdcEv969e2vWrFmaM2eOChYsqFOnTunUqVO6fPlyTpcG4BESEhKi8+fPKyIiQiEhIZo+fbrNQ6S6du2qESNGqGrVqvr000/VsGFDRUREqF27dmnGOnTokNq3b6+WLVsqIiJC586dU8uWLTV79my9+eab6tixo8LDw/XPP/8oJCTE5uFZf//9t5588knt3btXQ4YM0ccff6z8+fOrdevWWrRo0QP5LgAAQO6R6Us9f/31V9WpU8fmnX7Sjb/l3rRp021frXC/Jk+eLEkKCgqyaY+MjFRoaGi2HBMAblWlShVNmzbNun327FlNmzZNo0eP1s6dOzVjxgx17dpVX375paQbTzz28PDQ2LFjtXbtWjVq1Mj62f3792vTpk2qXbu2JCkgIEDBwcHq1q2b9u3bp5IlS0qSChcurNdff12//vqr9b+Bb7zxhkqWLKlt27ZZ72Xu1auX6tWrp8GDB+v5559/EF8HAADIJTK94teoUSPFxcWlaU9ISLD5A01WMwwj3R9CH4AHqUePHjbb9evX19mzZ5WYmGh93c2AAQNs+gwcOFCS9NNPP9m0BwQEWEOfJNWqVUuS9NRTT1lD383thw8fliTFxcXpl19+sa4+xsbGKjY2VmfPnlVwcLAOHjyo6OjorDhdAABgEple8TMMQxaLJU372bNnlT9//iwpCgAeVjcHMunGapwknTt3TseOHZOdnZ1Kly5t08fT01OFChXSsWPH7jiWq6urJMnb2zvd9nPnzkm6cYmoYRgaPny4hg8fnm6dMTExKlGiRGZODQAAmFiGg98LL7wgSbJYLAoNDbV5TUJycrL++usv1alTJ+srBIAckpxiaOuROMWcv6J/4248wCX1tQ63uvmVqOn95Vh6bjfW3Y6Req/foEGDFBwcnG7fW8MnAAB4tGU4+KX+jbNhGCpYsKCcnJys+/Lly6cnn3xS3bp1y/oKASAHrNh9UuFL9+hkwhVJUnzUf5KkNXtPqW399F/gXqpUKaWkpOjgwYMqX768tf306dOKj49XqVKlsqQ2Pz8/STfeP9SkSZMsGRMAAJhbhoNfZGSkpBuPIB80aBCXdQIwrRW7T6rnrCgZ6ez737y/5FrYTc0CvdLsa9GihYYNG6Zx48ZpypQp1vZPPvlEkvTMM89kSX0eHh4KCgrSlClT1LdvX3l52dZy5swZubu7Z8mxAACAOWT6Hr+RI0dmRx0A8FBITjEUvnRPuqEvVfjSPWoa4Cl7O9tLOitVqqTOnTtr6tSpio+PV8OGDbV161bNmDFDrVu3ztIHYE2cOFH16tVTxYoV1a1bN/n5+en06dPavHmz/vvvP+3cuTPLjgUAAHK/TAe/06dPa9CgQVqzZo1iYmJs7muRbtzvBwC51dYjcdbLO9NjSDqZcEVbj8Sptr9bmv1fffWV/Pz8NH36dC1atEienp4aOnRolv+lWUBAgLZv367w8HBNnz5dZ8+elYeHh6pUqaIRI0Zk6bEAAEDul+ngFxoaquPHj2v48OHy8vLK8EMMACA3iDmffugrVK+DCtXrkKZfaGiozWtl8uTJoxEjRtw1fB09ejTd9lv/Mk26cYl9eu1+fn6aMWPGHY8DAAAg3UPw27Bhg3777TdVrlw5G8oBgJzlUdAxS/tlRlhYmMLDw3XmzBkVLZr+A2SkG0EwKChI06dPv+N406dPV5cuXXTkyBH5+PhkbbEAACBXyfQL3L29vdP9m2cAMIOavkXk5eqo213LYJHk5eqomr5FHmRZAAAA9yXTwW/cuHEaMmTIbS9TAoDczN7OopEtAyQpTfhL3R7ZMiDNg10epP379+vLL7/MseMDAIDcJ9OXerZt21aXLl2Sv7+/nJ2dlTdvXpv9cXFxWVYcAOSEZoFemtyxqs17/CTJ09VRI1sGpPsqhwfJwcEhR48PAAByn0wHv3HjxmVDGQDwcGkW6KWmAZ7aeiROMeevyKPgjcs7H8RKX2xsrHr16qUVK1Yob9686tixo0aPHi1Hxxv3FaZ3j9/ff/+tvn37avPmzXJzc1OPHj1UvHjxdMdfvny5Ro0apaioKNnZ2alBgwb66KOPVKFCBWuf0NBQzZ8/X/v371fv3r21evVqOTk5qXPnzho9erTs7e2z9TsAAABZK9PBr3PnztlRBwA8dOztLOm+siG7hYSEyMfHRxEREdqyZYs+//xznTt3TjNnzky3/6lTp9SoUSNdv35dQ4YMUf78+TV16lQ5OTml6fvNN9+oc+fOCg4O1ujRo3Xp0iVNnjxZ9erV059//mnzEJjk5GQFBwerVq1aGjt2rFavXq2PP/5Y/v7+6tmzZ3adPgAAyAaZDn6S9M8//ygyMlL//POPPvvsM3l4eGj58uUqWbKkzd8YAwAyz9fXV0uWLJEk9e7dWy4uLpo0aZIGDRqkJ554Ik3/0aNH68yZM/r9999Vs2ZNSTf+kq5MmTI2/S5cuKB+/fqpa9eumjp1qrW9c+fOKlu2rEaNGmXTfuXKFbVt21bDhw+XJPXo0UNVq1bVtGnTCH4AAOQymX64y/r161WxYkX9/vvvWrhwoS5cuCBJ2rlzZ5a/oBgAHkW9e/e22e7bt68kadmyZen2X7ZsmZ588klr6JMkd3d3dejQwabfqlWrFB8fr5dfflmxsbHWH3t7e9WqVUtr165NM3aPHj1stuvXr6/Dhw/f03kBAICck+kVvyFDhuj999/XgAEDVLBgQWv7U089pQkTJmRpcQBgZskphs09hCn/96qcW1fq/P39ZWdnd9unKR87dky1atVK0162bFmb7YMHD0q68d/r9Li4uNhsOzo6yt3d3aatcOHCOnfu3O1PCgAAPJQyHfx27dqlOXPmpGn38PBQbGxslhQFAGa3YvfJNE8Nvb7tSLp9LZaseaBMSkqKpBv3+Xl6eqbZnyeP7f8SeIALAADmkengV6hQIZ08eVK+vr427X/++adKlCiRZYUBgFmt2H1SPWdFybil/cLV65KkOau26O3u//+/sYcOHVJKSorNg1duVqpUKetq3s32799vs+3v7y/pxl/UNWnS5N5PAAAA5DqZvsevXbt2Gjx4sE6dOiWLxaKUlBRt3LhRgwYNUqdOnbKjRgAwjeQUQ+FL96QJfTf7eNx4Jaf8/x7jx4+XJDVv3jzd/i1atNCWLVu0detWa9uZM2c0e/Zsm37BwcFycXHRqFGjlJSUlGacM2fOZOJMAABAbpLpFb9Ro0apd+/e8vb2VnJysgICApScnKz27dvrnXfeyY4aAcA0th6Js7m8Mz0XYk8qqGlzvfxiK23evFmzZs1S+/btValSpXT7v/XWW/rmm2/UrFkzvfHGG9bXOZQqVUp//fWXtZ+Li4smT56sV155RVWrVlW7du3k7u6u48eP66efflLdunW5VxsAAJPKdPDLly+fvvzySw0fPly7d+/WhQsXVKVKlTQPIwAApBVz/s6hT5LcWw1WyrEfNWTIEOXJk0d9+vTRmDFjbtvfy8tLa9euVd++ffXhhx/avMD9tddes+nbvn17FS9eXB9++KHGjBmjq1evqkSJEqpfv766dOly3+cHAAAeTvf0Hj9JKlmypEqWLJmVtQCA6XkUdLztvkL1OqhQvRuvYBg7dMZtXx6f3tM9K1asqHXr1qVpf/XVV9O0BQUFKSgo6I51Tp8+XdOnT0/THhYWprCwsDt+FgAAPHwyHfySk5M1ffp0rVmzRjExMdanxKX65Zdfsqw4ADCbmr5F5OXqqFMJV9K9z88iydPVUTV9izzo0gAAgIllOvi98cYbmj59up555hkFBgZm2WPGAeBRYG9n0ciWAeo5K0oWySb8pf7XdGTLANnb8d9WAACQdTId/L777jt9//33atGiRXbUAwCm1yzQS5M7Vk3zHj9PV0eNbBmgZoFeOVgdAAAwo3t6uEvp0qWzoxYAeGQ0C/RS0wBPbT0Sp5jzV+RR8Mblnaz0AQCA7JDp9/gNHDhQn332mQzjTm+hAgDcjb2dRbX93fRc5RKq7e9G6AMAANkm0yt+GzZs0Nq1a7V8+XJVqFBBefPmtdm/cOHCLCsOAAAAAHD/Mh38ChUqpOeffz47agEAAAAAZINMB7/IyMjsqAMAAAAAkE3u+QXuZ86c0f79+yVJZcuWlbu7e5YVBQAAAADIOpl+uMvFixf16quvysvLSw0aNFCDBg1UvHhxvfbaa7p06VJ21AgAAAAAuA+ZDn4DBgzQ+vXrtXTpUsXHxys+Pl5LlizR+vXrNXDgwOyoEQAAAABwHzJ9qeeCBQs0f/58BQUFWdtatGghJycnhYSEaPLkyVlZHwAAAADgPmV6xe/SpUsqVqxYmnYPDw8u9QQAAACAh1Cmg1/t2rU1cuRIXblyxdp2+fJlhYeHq3bt2llaHAAAAADg/mX6Us/PPvtMwcHBeuyxx1SpUiVJ0s6dO+Xo6Kiff/45ywsEAAAAANyfTAe/wMBAHTx4ULNnz9a+ffskSS+//LI6dOggJyenLC8QAAAAAHB/7uk9fs7OzurWrVtW1wIAAAAAyAb3FPz279+v8ePHa+/evZKk8uXLq0+fPipXrlyWFgcAAAAAuH+ZfrjLggULFBgYqD/++EOVKlVSpUqVFBUVpYoVK2rBggXZUSMAAAAA4D5kesXvrbfe0tChQ/Xuu+/atI8cOVJvvfWWXnzxxSwrDgAAAABw/zK94nfy5El16tQpTXvHjh118uTJLCkKAAAAAJB1Mh38goKC9Ntvv6Vp37Bhg+rXr58lRQEAAAAAsk6mL/Vs1aqVBg8erD/++ENPPvmkJGnLli2aN2+ewsPD9cMPP9j0BQAAAADkrEwHv169ekmSJk2apEmTJqW7T5IsFouSk5PvszwAAAAAwP3KdPBLSUnJjjoAAAAAANkk0/f4AQAAAAByl3t6gfu2bdu0du1axcTEpFkB/OSTT7KkMAAAADOyWCzq3bu3JkyYkNOlAHiEZDr4jRo1Su+8847Kli2rYsWKyWKxWPfd/O8AAAAAgIdDpoPfZ599pq+//lqhoaHZUA4AAAAAIKtl+h4/Ozs71a1bNztqAQAAAABkg0wHvzfffFMTJ07MjloAAAByrbCwMFksFh06dEihoaEqVKiQXF1d1aVLF126dClN/9mzZ6ts2bJydHRUtWrV9Ouvv9rsP3bsmHr16qWyZcvKyclJbm5uatOmjY4ePfqAzgiAmWT6Us9BgwbpmWeekb+/vwICApQ3b16b/QsXLsyy4gAAAHKbkJAQ+fr6KiIiQlFRUfrqq6/k4eGh0aNHW/usX79ec+fOVb9+/eTg4KBJkyapWbNm2rp1qwIDAyXdeJjepk2b1K5dOz322GM6evSoJk+erKCgIO3Zs0fOzs45dYoAcqFMB79+/fpp7dq1atSokdzc3HigCwAAwE2qVKmiadOmWbfPnj2radOm2QS/3bt3a/v27apWrZokqV27dipbtqxGjBhh/Uv0Z555Ri+99JLN2C1btlTt2rW1YMECvfLKKw/gbACYRaaD34wZM7RgwQI988wz2VEPAABArtajRw+b7fr162vRokVKTEyUi4uLJKl27drW0CdJJUuW1HPPPaelS5cqOTlZ9vb2cnJysu5PSkpSYmKiSpcurUKFCikqKorgByBTMn2PX5EiReTv758dtQAAAOQaySmGNv9zVkt2RGvzP2eVYhiSboS4mxUuXFiSdO7cOWtbmTJl0oz3+OOP69KlSzpz5owk6fLlyxoxYoS8vb3l4OCgokWLyt3dXfHx8UpISMiu0wJgUple8QsLC9PIkSMVGRnJteUAAOCRtGL3SYUv3aOTCVesbde3HZEk2dvbp/sZ4/+CYUb17dtXkZGR6t+/v2rXri1XV1dZLBa1a9dOKSkp9148gEdSplf8Pv/8cy1fvlzFihVTxYoVVbVqVZsfAAAAM1ux+6R6zoqyCX2SdOHqdUnSmr2n7jrGwYMH07QdOHBAzs7Ocnd3lyTNnz9fnTt31scff6yXXnpJTZs2Vb169RQfH3//JwHksNSn4MbGxj6Q4x09elQWi0Vjx47N1uOsW7dOFotF8+fPz7IxU7+rm/n4+GT6veqZXvFr3bp1Zj8CAABgCskphsKX7tGd1u7G/HxAL9WtIHu72z8Ab/PmzYqKirL+pfm///6rJUuWqFmzZtYVQ3t7+zSrhOPHj1dycvJ9nweA+zNnzhzFxMSof//+OV1KhmU6+I0cOTI76gAAAHjobT0Sl2al71anE69o65E41fZ3u22fwMBABQcH27zOQZLCw8OtfZ599ll98803cnV1VUBAgDZv3qzVq1fLze324wJ4MObMmaPdu3ebO/il+uOPP7R3715JUoUKFVSlSpUsKwoAAOBhFHP+zqEvo/0aNmyo2rVrKzw8XMePH1dAQICmT5+uJ554wtrns88+k729vWbPnq0rV66obt26Wr16tYKDg+/rHAA8mjJ9j19MTIyeeuop1ahRQ/369VO/fv1UrVo1NW7c2PoUKgAAADPyKOh4232F6nVQqcE/yt7Z1aZfaGioDMOQj4+PpBsPeZkwYYI6dOigAwcO6MqVK4qKilJQUJDteIUK6euvv9aZM2d0/vx5rVixQmXLltXRo0c1ffr0bDg74MGLjY1VSEiIXFxc5ObmpjfeeENXrvz/vziJjIzUU089JQ8PDzk4OCggIECTJ09OM8727dsVHBysokWLysnJSb6+vnr11VfveOzUS6mLFi1qfX+mJM2aNUvVqlWTk5OTihQponbt2unff/+17g8KCtJPP/2kY8eOyWKxyGKxWH9/p0pOTtawYcPk6emp/Pnzq1WrVjZjSNJvv/2mNm3aqGTJknJwcJC3t7fefPNNXb58OcPfX2ZkesWvb9++On/+vP7++2+VL19ekrRnzx517txZ/fr107fffpvlRQIAADwMavoWkZero04lXEn3Pj+LJE9XR9X0LfKgSwNypZCQEPn4+CgiIkJbtmzR559/rnPnzmnmzJmSpMmTJ6tChQpq1aqV8uTJo6VLl6pXr15KSUlR7969Jd1YmHr66afl7u6uIUOGqFChQjp69KhNmLtVcnKyevbsKUmaPXu2XnjhBUnSBx98oOHDhyskJERdu3bVmTNnNH78eDVo0EB//vmnChUqpLffflsJCQn677//9Omnn0qSChQoYDP+Bx98IIvFosGDBysmJkbjxo1TkyZNtGPHDus7OufNm6dLly6pZ8+ecnNz09atWzV+/Hj9999/mjdvXtZ+0bqH4LdixQqtXr3aGvokKSAgQBMnTtTTTz+dpcUBAAA8TOztLBrZMkA9Z0XJItmEv9RHuYxsGXDHB7sA+P98fX21ZMkSSVLv3r3l4uKiSZMmadCgQXriiSe0fv16a1CSpD59+qhZs2b65JNPrMFv06ZNOnfunFauXKnq1atb+77//vvpHvP69evq2LGjfvjhB0myXj597NgxjRw5Uu+//76GDRtm7f/CCy+oSpUqmjRpkoYNG6amTZuqRIkSOnfunDp27JjuMeLi4rR3714VLFhQklS1alWFhIToyy+/VL9+/SRJo0ePtjm37t27q3Tp0ho2bJiOHz+e5p2g9yvTl3qmpKQob968adrz5s3LO2UAAIDpNQv00uSOVeXpanvZp6eroyZ3rKpmgV45VBmQ+6SGt1R9+/aVJC1btkySbIJRQkKCYmNj1bBhQx0+fFgJCQmSblwWLUk//vijkpKS7ni8a9euqU2bNvrxxx/TrKotXLhQKSkpCgkJUWxsrPXH09NTZcqU0dq1azN8Xp06dbKGPkl66aWX5OXlZT2vW8/t4sWLio2NVZ06dWQYhv78888MHyujMr3i99RTT+mNN97Qt99+q+LFi0uSoqOj9eabb6px48ZZXuCtJk6cqDFjxujUqVOqVKmSxo8fr5o1a2b7cQEAAFI1C/RS0wBPbT0Sp5jzV+RR8Mblnaz0AelLTjFsfr+k/N/9dWXKlLHp5+/vLzs7Ox09elSStHHjRo0cOVKbN2/WpUuXbPomJCTI1dVVDRs21Isvvqjw8HB9+umnCgoKUuvWrdW+fXs5ODjYfCYiIkIXLlzQ8uXLVadOHZt9Bw8elGEYaWpKld7i1+3cOobFYlHp0qWt5yVJx48f14gRI/TDDz/o3Llzac4tq2U6+E2YMEGtWrWSj4+PvL29Jd1490xgYKBmzZqV5QXebO7cuRowYIC++OIL1apVS+PGjVNwcLD2798vDw+PbD02AADAzeztLHd8ZQOAG1bsPqnwpXtsXoVyfduRdPve/KLyf/75R40bN1a5cuX0ySefyNvbW/ny5dOyZcv06aefWq82TH1h+pYtW7R06VL9/PPPevXVV/Xxxx9ry5YtNvffBQcHa8WKFfroo4/03Xff2Rw7JSVFFotFy5cvt75P82a33sd3P5KTk9W0aVPFxcVp8ODBKleunPLnz6/o6GiFhoZmy5WUmQ5+3t7eioqK0urVq7Vv3z5JUvny5dWkSZMsL+5Wn3zyibp166YuXbpIkr744gv99NNP+vrrrzVkyJBsPz4AAACAjFux+6R6zopK8zCkC1evS5LmrNqit7v7WtsPHTqklJQU+fj4aOnSpbp69ap++OEHm/vdbnfJ5ZNPPqknn3xSH3zwgebMmaMOHTrou+++U9euXW369OjRQ88++6w6d+5s83l/f38ZhiFfX189/vjjdzyvmwNqeg4ePGizbRiGDh06ZH1ly65du3TgwAHNmDFDnTp1svZbtWrVHce9H/f0Hj+LxaKmTZuqadOmWV3PbV27dk1//PGHhg4dam2zs7NTkyZNtHnz5nQ/c/XqVV29etW6nZiYKElKSkq66/W/mZU6XlaPi5zFvJoPc2o+zKn5MKfmxLyaz93mNDnFUMRPfyuffdpn4Nr/X276dNx4Dez8ovUy6c8++0yS1KRJE23YsEHSjRyQeoyEhARFRkZaj5uUlKRz586pUKFCNmGsQoUKkqRLly7Z/Nk/OTlZDRs21KxZs/Tyyy9LknV17YUXXtDQoUMVHh6uWbNm2YxnGIbi4uLk5nZjlT9//vx3vBxz5syZGjp0qPU+v/nz5+vkyZMaPHjwjfP/vxXF1FdKpP576vlnhwwHv19++UV9+vTRli1b5OLiYrMvISFBderU0RdffKH69etneZHSjXd8JCcnq1ixYjbtxYoVs6483ioiIkLh4eFp2leuXClnZ+dsqTM7UzpyDvNqPsyp+TCn5sOcmhPzaj53mtMB5dJv//afFM2VVODSCTWoX09VqlTR/v37tX79ejVo0EDR0dHKly+f8uTJoyZNmig4OFhXrlzRypUr5eh448FKa9euVbFixfTDDz9oxYoVqlWrljw9PXX58mWtWrVKzs7OcnR01LJly3T69GlJ0r59+7Rs2TLlzZtX3bt316RJk/Tmm28qMjJS/v7+ev/99zV06FAdPXpUrVu3VsGCBXXkyBEtWrRI3bt316BBgyRJ1apVs96GVqNGDRUoUEAtW7a0nl+RIkVUr149denSRadPn9a4ceNUunRpdevWTZJUrlw5+fv7a9CgQYqOjpaLi4sWLFiQ5l6/rJTh4Ddu3Dh169YtTeiTJFdXV73++uv65JNPsi343YuhQ4dqwIAB1u3ExER5e3vr6aefTvc87kdSUpJWrVqlpk2bZurGTzzcmFfzYU7Nhzk1H+bUnJhX87nbnC7bdVJvLfgr3c/GRv/fywWCByvvPz/q22+/VZ48edSrVy99+OGH1nDn5eWlkSNHaubMmfL09FS/fv3k7u6ubt26qVGjRvLx8ZGXl5cuXryozZs36/Tp03J1dVX16tU1YsQIVa1aVZKsD1UpV66cWrRoIUmqV6+eJk2apOnTp6to0aIaM2aMhgwZoscff1yffvqpdQEpNT+0atXKWn+vXr20Y8cORUZG6tNPP1WpUqVsgt+wYcP0119/KSIiQufPn1fjxo01adIk6+JT3rx5tXTpUvXr108RERFydHTU888/rz59+qhSpUr3MSu3ZzFuXl+8g1KlSmnFihU27++72b59+/T000/r+PHjWVpgqmvXrsnZ2Vnz589X69atre2dO3dWfHy89f0fd5KYmChXV1clJCRkS/BbtmyZWrRowX/MTIR5NR/m1HyYU/NhTs2JeTWfu83p5n/O6uUvt9x1nG+7PZkjD0rKzmzwMMrwe/xOnz59x9+kefLk0ZkzZ7KkqPTky5dP1apV05o1a6xtKSkpWrNmjWrXrp1txwUAAACQeTV9i8jL1VG3ewyKRZKX641XoSD7ZTj4lShRQrt3777t/r/++kteXtn7wtIBAwboyy+/1IwZM7R371717NlTFy9etD7lEwAAAHiQtm3bpjp16ih//vyyWCzasWPHAzu2j4+Pnn322Swb7+jRo7JYLJo+fbq1LSws7K5PsLwdezuLRrYMkHQj5BkpyTq39mv9NylUx0a31OmF72tkywDlsbdTWFjY/Z8A7ijD9/i1aNFCw4cPV7NmzazX3Ka6fPmyRo4cmaW/8NLTtm1bnTlzRiNGjNCpU6dUuXJlrVixIs0DXwAAAIDslpSUpDZt2sjR0VGffvqpnJ2dVapUqSw9xp49e/T9998rNDRUPj4+WTr2g9As0EuTO1ZV+NI9OrB+sRK3LlTB6s/Jw7ecujevqWaB2btwhP8vw8HvnXfe0cKFC/X444+rT58+Klu2rKQb9/ZNnDhRycnJevvtt7Ot0FR9+vRRnz59sv04AAAAwJ38888/OnbsmL788kubd8VlpT179ig8PFxBQUG5MvhJN8Jf0wBPBW+coB0enlr63TTV9C1ifYUDHowMB79ixYpp06ZN6tmzp4YOHWp954TFYlFwcLAmTpzIyhsAAAAeGTExMZKkQoUK5WwhuYC9nUUplxLk6e6WIw9yQSbu8ZNuPNlz2bJlio2N1e+//64tW7YoNjZWy5Ytk6+vb3bVCAAAADxUQkND1bBhQ0lSmzZtZLFYFBQUJOnG+6/r16+v/Pnzq1ChQnruuee0d+/eNGP8+eefat68uVxcXFSgQAE1btxYW7b8/6dgTp8+XW3atJEkNWrUSBaLRRaLRevWrbMZZ+XKlapcubIcHR0VEBCghQsX2uyPi4vToEGDVLFiRRUoUEAuLi5q3ry5du7cmSXfxbvvviuLxaJDhw4pNDRUhQoVkqurq7p06aJLly5Z7x1cu3at/v7779ueB7JXhlf8bla4cGHVqFEjq2sBAAAAcoXXX39dJUqU0KhRo9SvXz/VqFFDxYoV0+rVq9W8eXP5+fkpLCxMly9f1vjx41W3bl1FRUVZL9f8+++/Vb9+fbm4uOitt95S3rx5NWXKFAUFBWn9+vWqVauWGjRooH79+unzzz/XsGHDrK9Vu/n1agcPHlTbtm3Vo0cPde7cWZGRkWrTpo1WrFihpk2bSpIOHz6sxYsXq02bNvL19dXp06c1ZcoUNWzYUHv27FHx4sWz5DsJCQmRr6+vIiIiFBUVpa+++koeHh4aMWKEvvnmG33wwQe6cOGCIiIi0pwHst89BT8AAADgUVa7dm1dvXpVo0aNUv369fXSSy9JkqpUqaIiRYpo8+bNKlLkxmsKWrdurSpVqmjkyJGaMWOGpBvPz0hKStKGDRvk5+cnSerUqZPKli2rt956S+vXr5efn5/q16+vzz//XE2bNrWuKN7swIEDWrBggV544QVJ0muvvaZy5cpp8ODB1uBXsWJFHThwQHZ2//9iv1deeUXlypXTtGnTNHz48Cz5TqpUqaJp06ZZt8+ePatp06Zp9OjR6tixo7766ivZ29urY8eOWXI8ZE6mLvUEAAAAkL6TJ09qx44dCg0NtYY+SXriiSfUtGlTLVu2TJKUnJyslStXqnXr1tbQJ0leXl5q3769NmzYoMTExAwds3jx4nr++eet2y4uLurUqZP+/PNPnTp1SpLk4OBgDX3Jyck6e/asChQooLJlyyoqKuq+zztVjx49bLbr16+vs2fPZvhckL0IfgAAAEAWOHbsmCRZn35/s/Llyys2NlYXL17UmTNndOnSpdv2S0lJ0b///puhY5YuXTrNe/Yef/xxSTfeyydJKSkp+vTTT1WmTBk5ODioaNGicnd3119//aWEhITMnOIdlSxZ0ma7cOHCkqRz585l2TFw77Is+KWkpOjHH3/MquEAAACAh05yiqHN/5zVkh3R+js660JTdho1apQGDBigBg0aaNasWfr555+1atUqVahQQSkpKZkeL/U7WLbrpCTp/x72L3t7+3T7p74NADnrvu/xO3TokL7++mtNnz5dZ86cUVJSUlbUBQAAADxUVuw+qfCle3Qy4Yok6crxPZKkP4+f00uS9eXt+/fvT/PZffv2qWjRosqfP78cHR3l7Ox82352dnby9vaWpDSrebc6dOiQDMOw6XfgwAFJsj5IZv78+WrUqJHN/XeSFB8fr6JFi2bgzP+/m78DB3tDH9WUvtlyLFNjIGfc04rf5cuXNXPmTDVo0EBly5bVpk2bNGLECP33339ZXR8AAACQ41bsPqmes6Ksoe9mX/56WCt2n5SXl5cqV66sGTNmKD4+3rp/9+7dWrlypVq0aCHpxsrY008/rSVLllgvx5Sk06dPa86cOapXr55cXFwkSfnz55ckm/FuduLECS1atMi6nZiYqJkzZ6py5cry9PS0Hu/WVbd58+YpOjo6S76Di1evS5LW7D2VqfHwYGVqxW/btm366quv9N1338nf318dOnTQpk2bNGnSJAUEBGRXjQAAAECOSU4xFL50j+50wWL40j1qGuCpMWPGqHnz5qpdu7Zee+016+scXF1dFRYWZu3//vvva9WqVapXr5569eqlPHnyaMqUKbp69ao++ugja7/KlSvL3t5eo0ePVkJCghwcHPTUU0/Jw8ND0o37+V577TVt27ZNxYoV09dff63Tp08rMjLSOsazzz6rd999V126dFGdOnW0a9cuzZ492+bBMvfzHaS2jfn5gF6qW0H2dndepUTOyPCK3xNPPKE2bdrIzc1NmzZtUlRUlAYOHHjX5WcAAAAgN9t6JC7dlb5UhqSTCVe09UicmjRpohUrVsjNzU0jRozQ2LFj9eSTT2rjxo3y9fW1fqZChQr67bffFBgYqIiICIWHh6tUqVJau3atatWqZe3n6empL774QjExMXrttdf08ssva8+ePdb9ZcqU0dy5c7Vs2TINGTJESUlJmjt3roKDg619hg0bpoEDB+rnn3/WG2+8oaioKP3000/Wy0mz4juQpNOJN74DPJwyvOK3f/9+tW3bVo0aNWJ1DwAAAI+MmPPpBx7Hkk+o1OAf0/Rr3LixGjdufNdxq1SpohUrVty1X9euXdW1a9c07TdfJvr000/f9vMODg4aO3asxo4da9O+bt06m20fH580l4SGhYUpLCxMS3bc/rLQog3aq2DdDpJsv6vQ0FCFhobe9nipePjLg5HhFb/Dhw+rbNmy6tmzpx577DENGjRIf/75Jyt+AAAAMDWPgo5Z2i834jvI/TIc/EqUKKG3335bhw4d0jfffKNTp06pbt26un79uqZPn259ehAAAABgJjV9i8jL1VG3W+6wSPJydVRN3yK36ZH78R3kfvf0VM+nnnpKs2bN0smTJzVhwgT98ssvKleunJ544omsrg8AAADIUfZ2Fo1seeNWp1uDT+r2yJYBpn6oCd9B7ndfL3B3dXVVr169tH37dkVFRSkoKCiLygIAAAAeHs0CvTS5Y1V5utpeyujp6qjJHauqWaBXDlX24NzuOyjm8uh8B7lZhh/ucvnyZa1atUqNGjVSwYIFbfYlJibq+PHjGjNmTJYXCAAAADwMmgV6qWmAp7YeiVPM+SvyKHjj0sZHaZXL5jtIuCj9+6d+7t9Ajg75cro03EWGg9/UqVP1ww8/qFWrVmn2ubi46PPPP9e///6r3r17Z2mBAAAAwMPC3s6i2v5uOV1Gjkr9DpKSXLTs3z8fqeCbm2X4Us/Zs2erf//+t93fv39/zZgxIytqAgAAAABkoQwHv4MHD6pSpUq33f/EE0/o4MGDWVIUAAAAACDrZDj4Xb9+XWfOnLnt/jNnzuj69etZUhQAAAAAIOtkOPhVqFBBq1evvu3+lStXqkKFCllSFAAAAAAg62Q4+L366qt677339OOPP6bZt3TpUn3wwQd69dVXs7Q4AAAAAMD9y/BTPbt3765ff/1VrVq1Urly5VS2bFlJ0r59+3TgwAGFhISoe/fu2VYoAAAAAODeZOoF7rNmzdJ3332nMmXK6MCBA9q/f7/Kli2rb7/9Vt9++2121QgAAAAAuA8ZXvFLFRISopCQkOyoBQAAAACQDTK84peSkqLRo0erbt26qlGjhoYMGaLLly9nZ20AAAAAgCyQ4eD3wQcfaNiwYSpQoIBKlCihzz77TL17987O2gAAAAAAWSDDwW/mzJmaNGmSfv75Zy1evFhLly7V7NmzlZKSkp31AQAAAADuU4aD3/Hjx9WiRQvrdpMmTWSxWHTixIlsKQwAAAAAkDUyHPyuX78uR0dHm7a8efMqKSkpy4sCAAAAAGSdDD/V0zAMhYaGysHBwdp25coV9ejRQ/nz57e2LVy4MGsrBAAAAADclwwHv86dO6dp69ixY5YWAwAAAADIehkOfpGRkdlZBwAAAAAgm2T4Hj8AAAAAQO5E8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMLlcEv6NHj+q1116Tr6+vnJyc5O/vr5EjR+ratWs5XRoAAAAAPPTy5HQBGbFv3z6lpKRoypQpKl26tHbv3q1u3brp4sWLGjt2bE6XBwAAAAAPtVwR/Jo1a6ZmzZpZt/38/LR//35NnjyZ4AcAAAAAd5Ergl96EhISVKRIkTv2uXr1qq5evWrdTkxMlCQlJSUpKSkpS+tJHS+rx0XOYl7Nhzk1H+bUfJhTc2JezSe3z2lurfteWQzDMHK6iMw6dOiQqlWrprFjx6pbt2637RcWFqbw8PA07XPmzJGzs3N2lggAAADgIXbp0iW1b99eCQkJcnFxyelysl2OBr8hQ4Zo9OjRd+yzd+9elStXzrodHR2thg0bKigoSF999dUdP5veip+3t7diY2OzfHKTkpK0atUqNW3aVHnz5s3SsZFzmFfzYU7Nhzk1H+bUnJhX88ntc5qYmKiiRYs+MsEvRy/1HDhwoEJDQ+/Yx8/Pz/rvJ06cUKNGjVSnTh1NnTr1ruM7ODjIwcEhTXvevHmz7Rdndo6NnMO8mg9zaj7Mqfkwp+bEvJpPbp3T3Fjz/cjR4Ofu7i53d/cM9Y2OjlajRo1UrVo1RUZGys4uV7yJAgAAAAByXK54uEt0dLSCgoJUqlQpjR07VmfOnLHu8/T0zMHKAAAAAODhlyuC36pVq3To0CEdOnRIjz32mM2+XPhsGgAAAAB4oHLF9ZKhoaEyDCPdHwAAAADAneWK4AcAAAAAuHcEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/DLJXx8fBQaGprTZQAAAADIhQh+AAAAAGByBD8AAAAAMDmCHwAAAACYHMEvh4WFhclisWjfvn0KCQmRi4uL3Nzc9MYbb+jKlSu3/VxcXJwGDRqkihUrqkCBAnJxcVHz5s21c+dOm37r1q2TxWLR999/rw8++ECPPfaYHB0d1bhxYx06dCjNuL///ruaNWsmV1dXOTs7q2HDhtq4cWOWnzcAAACABydPTheAG0JCQuTj46OIiAht2bJFn3/+uc6dO6eZM2em2//w4cNavHix2rRpI19fX50+fVpTpkxRw4YNtWfPHhUvXtym/4cffig7OzsNGjRICQkJ+uijj9ShQwf9/vvv1j6//PKLmjdvrmrVqmnkyJGys7NTZGSknnrqKf3222+qWbNmtn4HAAAAALIHwe8h4evrqyVLlkiSevfuLRcXF02aNEmDBg3SE088kaZ/xYoVdeDAAdnZ/f9F21deeUXlypXTtGnTNHz4cJv+V65c0Y4dO5QvXz5JUuHChfXGG29o9+7dCgwMlGEY6tGjhxo1aqTly5fLYrFIkl5//XVVqFBB77zzjlauXJldpw8AAAAgG3Gp50Oid+/eNtt9+/aVJC1btizd/g4ODtbQl5ycrLNnz6pAgQIqW7asoqKi0vTv0qWLNfRJUv369SXdWDmUpB07dujgwYNq3769zp49q9jYWMXGxurixYtq3Lixfv31V6WkpNz/iQIAAAB44FjxywHJKYa2HolTzPkr+jfukiSpTJkyNn38/f1lZ2eno0ePpjtGSkqKPvvsM02aNElHjhxRcnKydZ+bm1ua/iVLlrTZLly4sCTp3LlzkqSDBw9Kkjp37nzbuhMSEqyfAwAAAJB7EPwesBW7Typ86R6dTLjx4Jb4qP8kSev3x8jX19faL/VSy9sZNWqUhg8frldffVXvvfeeihQpIjs7O/Xv3z/dlTl7e/t0xzEMQ5KsnxkzZowqV66cbt8CBQrc+eQAAAAAPJQIfg/Qit0n1XNWlIx09g2JXCnPx0qqWaCXJOnQoUNKSUmRj49PumPNnz9fjRo10rRp02za4+PjVbRo0UzX5u/vL0lycXFRkyZNMv15AAAAAA8v7vF7QJJTDIUv3ZNu6JOkxKifFL50j5JTbvQYP368JKl58+bp9re3t7eu1qWaN2+eoqOj76m+atWqyd/fX2PHjtWFCxfS7D9z5sw9jQsAAAAg57Hi94BsPRJnvbwzPdcTTmvn18M0+NpLOn3oL82aNUvt27dXpUqV0u3/7LPP6t1331WXLl1Up04d7dq1S7Nnz5afn9891WdnZ6evvvpKzZs3V4UKFdSlSxeVKFFC0dHRWrt2rVxcXLR06dJ7GhsAAABAziL4PSAx528f+iTJvdVgxW+YpUlj3pVjvrzq06ePxowZc9v+w4YN08WLFzVnzhzNnTtXVatW1U8//aQhQ4bcc41BQUHavHmz3nvvPU2YMEEXLlyQp6enatWqpddff/2exwUAAACQswh+D4hHQcc77rdzdpF766H6ttuTqu2f9qmctz7d08HBQWPHjtXYsWNt2tetW2ezHRQUlOaSUEny8fFJt71y5cpasGDBHWsFAAAAkLtwj98DUtO3iLxcHXW7Z3VaJHm5Oqqmb5EHWRYAAACARwDB7wGxt7NoZMsASbpt+BvZMkD2dnd+jQMAAAAAZBbB7wFqFuilyR2rytM17WWfY9o8YX2VAwAAAABkJe7xe8CaBXqpaYCnth6JU8z5K/Lo9qRq+s5mpQ8AAABAtiH45QB7O0u6D3ABAAAAgOzApZ4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AHhpXrlxRSkpKTpcBAABgOgQ/AJkWHR2t1157TcWLF5eDg4N8fX3Vs2dPXbt2TXFxcRo0aJAqVqyoAgUKyMXFRc2bN9fOnTttxli3bp0sFou+++47vfPOOypRooScnZ2VmJiYQ2cFAABgXnlyuoDMunr1qmrVqqWdO3fqzz//VOXKlXO6JOCRcuLECdWsWVPx8fHq3r27ypUrp+joaM2fP1+XLl3S4cOHtXjxYrVp00a+vr46ffq0pkyZooYNG2rPnj0qXry4zXjvvfee8uXLp0GDBunq1avKly9fDp0ZAACAeeW64PfWW2+pePHiaVYPADwYQ4cO1alTp/T777+revXq1vZ3331XhmGoYsWKOnDggOzs/v8FBa+88orKlSunadOmafjw4TbjXblyRdu3b5eTk9MDOwcAAIBHTa661HP58uVauXKlxo4dm9OlAI+klJQULV68WC1btrQJfaksFoscHBysoS85OVlnz55VgQIFVLZsWUVFRaX5TOfOnQl9AAAA2SzXrPidPn1a3bp10+LFi+Xs7Jyhz1y9elVXr161bqfeO5SUlKSkpKQsrS91vKweFzmLebV1+vRpJSYmqnz58rf9TlJSUjR+/HhNmTJFR44cUXJysnVfkSJFrJ+7fv26JMnb2/uBfr/Mqfkwp+bDnJoT82o+uX1Oc2vd9ypXBD/DMBQaGqoePXqoevXqOnr0aIY+FxERofDw8DTtK1euzHB4zKxVq1Zly7jIWczrDfHx8ZKkf/75R8uWLUu3z/fff685c+aocePGeu6551SgQAHZ2dlp2rRpOnPmjPVzu3btkiTt27fvtmNlJ+bUfJhT82FOzYl5NZ/cOqeXLl3K6RIeqBwNfkOGDNHo0aPv2Gfv3r1auXKlzp8/r6FDh2Zq/KFDh2rAgAHW7cTERHl7e+vpp5+Wi4vLPdV8O0lJSVq1apWaNm2qvHnzZunYyDmP+ryu3ntaHy7fp1OJVyRJhlFY9g7O+jc2QS1atEj3MyNGjFBQUJCWL19u0z516lS5ublZP5c/f35JUpUqVW47VnZ41OfUjJhT82FOzYl5NZ/cPqeP2pPEczT4DRw4UKGhoXfs4+fnp19++UWbN2+Wg4ODzb7q1aurQ4cOmjFjRrqfdXBwSPMZScqbN2+2/eLMzrGRcx7FeV2x+6R6zdkpQ5Jk+b9WezmWeVJb1q3W5IVr1K9tM5vPGIahPHlu/Gfl5u9r3rx5io6OVunSpa3tqf3y5MmTI9/tozinZsecmg9zak7Mq/nk1jnNjTXfjxwNfu7u7nJ3d79rv88//1zvv/++dfvEiRMKDg7W3LlzVatWrewsEXgkJacYCl+65/9Cn61CDTrpypE/9eYrz+ufza+rQkCATp48qXnz5mnDhg169tln9e6776pLly6qU6eOdu3apdmzZ8vPz++BnwcAAABuyBX3+JUsWdJmu0CBApIkf39/PfbYYzlREmBqW4/E6WTClXT35SlYVJ6dPlb8b7M085vZunzxvEqUKKHmzZvL2dlZw4YN08WLFzVnzhzNnTtXVatW1U8//aQhQ4Y84LMAAABAqlwR/AA8WDHn0w99qfK4eKjoMwP0WbvKeq5yiTT7x44dm+a1K+vWrbPZDgoKkmGkt6YIAACArJYrg5+Pjw9/YASykUdBxyztBwAAgJyVq17gDuDBqOlbRF6ujtZHutzKIsnL1VE1fYs8yLIAAABwjwh+ANKwt7NoZMsASUoT/lK3R7YMkL3d7aIhAAAAHiYEPwDpahbopckdq8rT1fZyTk9XR03uWFXNAr1yqDIAAABkVq68xw/Ag9Es0EtNAzy19UicYs5fkUfBG5d3stIHAACQuxD8ANyRvZ1Ftf3dcroMAAAA3Acu9QQAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwBuY/r06bJYLNq+fftd+wYFBSkoKCjTx7BYLAoLC8t8cQAAAJlA8AMAAAAAk+MF7gCQBVauXJnTJQAAANwWwQ8AskC+fPlyugQAAIDb4lJPAKYxf/58WSwWrV+/Ps2+KVOmyGKxaPfu3ZKkffv26aWXXlKRIkXk6Oio6tWr64cffkh33KtXr2rAgAFyd3dX/vz59fzzz+vMmTM2fdK7x+/KlSsKCwvT448/LkdHR3l5eemFF17QP//8c8fziI6O1quvvqpixYrJwcFBFSpU0Ndff52JbwIAAMAWwQ+AaTzzzDMqUKCAvv/++zT75s6dqwoVKigwMFDHjx9X/fr1tXfvXg0ZMkQff/yx8ufPr9atW2vRokVpPtu3b1/t3LlTI0eOVM+ePbV06VL16dPnjrUkJyfr2WefVXh4uKpVq6aPP/5Yb7zxhhISEqzhMz2nT5/Wk08+qdWrV6tPnz767LPPVLp0ab322msaN25cpr8TAAAAiUs9AZiIk5OTWrZsqfnz5+vzzz+Xvb29JOnUqVNav3699emZX331lby9vbV9+3Y5ODhIknr16qV69epp8ODBev75523GdXNz08qVK2WxWCRJKSkp+vzzz5WQkCBXV9d0a5k5c6bWrFmjTz75RG+++aa1fciQITIM47bn8Pbbbys5OVm7du2Sm5ubJKlHjx56+eWXFRYWptdff11OTk739gUBAIBHFit+AEylbdu2iomJ0bp166xt8+fPV0pKitq2bau4uDjt2rVLL730ks6fP6/Y2FjFxsbq7NmzCg4O1sGDBxUdHW0zZvfu3a2hT5Lq16+v5ORkHTt27LZ1LFiwQEWLFlXfvn3T7Lt5rJsZhqEFCxaoZcuWMgzDWltsbKyCg4OVkJCgqKioTH4jAAAArPgBMJlmzZrJ1dVVc+fOVePGjSXduMyzcuXKevzxx7Vp0yYZhqGwsLDbvj8vJiZGJUqUsG6XLFnSZn/hwoUlSefOnbttHf/884/Kli2rPHky/p/ZM2fOKD4+XlOnTtXUqVNvWxsAAEBmEfwA5GrJKYa2HolTzPkr8ijoqJq+Raz36k2aNEmnT5/Wxo0bNWrUKEk3LtOUpAEDBqh58+bpjlm6dGmb7dRLRm91p0s270VqbR07dlTnzp3T7fPEE09k6TEBAMCjgeAHINdasfukwpfu0cmEK9Y2L1dHtajVVLEzZmjNmjXau3evDMNQ27ZtJUm+vr6SpDx58qhJkybZVpu/v79+//13JSUlKW/evBn6jLu7uwoWLKjk5ORsrQ0AADx6uMcPQK60YvdJ9ZwVZRP6JOlUwhVNO1xABV0La+7cuZo7d65q1qxpDXweHh4KDAzUV199pZMnT6YZ99bXNNyrF198UbGxsZowYUKafbdbKbS3t9eLL76oBQsWpPvkz6yqDQAAPHpY8QOQ6ySnGApfukfpxSdDksU+j5zKPKl58+bp4sWLGjt2rE2f119/XSNGjFDFihXVrVs3+fn56fTp09q8ebP+++8/7dy5875r7NSpk2bOnKkBAwZo69atql+/vi5evKjVq1erV69eeu6559L93Icffqi1a9eqVq1a6tatmwICAhQXF6eoqCitXr1acXFx910bAAB49BD8AOQ6W4/EpVnpu5khSf51dWH7clksFoWEhNjs9/b21ubNmzVq1ChNnz5dZ8+elYeHh6pUqaIRI0ZkSY329vZatmyZPvjgA82ZM0cLFiyQm5ub6tWrp4oVK972c8WKFdPWrVv17rvvauHChZo0aZLc3NxUoUIFjR49OktqAwAAjx6CH4BcJ+b87UNfKiefylr85396rnKJdPf7+flpxowZdxwjNDRUoaGhadqDgoLSXK558+sjrDU4Oen999/X+++/f9tjpHfZp4eHhyZMmJDuZaIAAAD3gnv8AOQ6HgUds7QfAACA2RH8AOQ6NX2LyMvVUem/Bl2y6MbTPWv6FnmQZQEAADy0CH4Ach17O4tGtgyQpDThL3V7ZMsA2dvdLhoCAAA8Wgh+AHKlZoFemtyxqjxdbS/n9HR11OSOVdUs0CuHKgMAAHj48HAXALlWs0AvNQ3w1NYjcYo5f0UeBW9c3slKHwAAgC2CH4Bczd7Ootr+bjldBgAAwEONSz0BAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMjuAHAAAAACZH8AMAAAAAkyP4AQAAAIDJEfwAAAAAwOQIfgAAAABgcgQ/AAAAADA5gh8AAAAAmBzBDwAAAABMLk9OF/AgGYYhSUpMTMzysZOSknTp0iUlJiYqb968WT4+cgbzaj7Mqfkwp+bDnJoT82o+uX1OUzNBakYwu0cq+J0/f16S5O3tncOVAAAAAHgYnD9/Xq6urjldRrazGI9KxJWUkpKiEydOqGDBgrJYLFk6dmJiory9vfXvv//KxcUlS8dGzmFezYc5NR/m1HyYU3NiXs0nt8+pYRg6f/68ihcvLjs7898B90it+NnZ2emxxx7L1mO4uLjkyl/4uDPm1XyYU/NhTs2HOTUn5tV8cvOcPgorfanMH20BAAAA4BFH8AMAAAAAkyP4ZREHBweNHDlSDg4OOV0KshDzaj7Mqfkwp+bDnJoT82o+zGnu8kg93AUAAAAAHkWs+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYJfNvrpp59Uq1YtOTk5qXDhwmrdunVOl4QscPXqVVWuXFkWi0U7duzI6XJwj44eParXXntNvr6+cnJykr+/v0aOHKlr167ldGnIpIkTJ8rHx0eOjo6qVauWtm7dmtMl4R5FRESoRo0aKliwoDw8PNS6dWvt378/p8tCFvrwww9lsVjUv3//nC4F9yE6OlodO3aUm5ubnJycVLFiRW3fvj2ny8JdEPyyyYIFC/TKK6+oS5cu2rlzpzZu3Kj27dvndFnIAm+99ZaKFy+e02XgPu3bt08pKSmaMmWK/v77b3366af64osvNGzYsJwuDZkwd+5cDRgwQCNHjlRUVJQqVaqk4OBgxcTE5HRpuAfr169X7969tWXLFq1atUpJSUl6+umndfHixZwuDVlg27ZtmjJlip544omcLgX34dy5c6pbt67y5s2r5cuXa8+ePfr4449VuHDhnC4Nd8HrHLLB9evX5ePjo/DwcL322ms5XQ6y0PLlyzVgwAAtWLBAFSpU0J9//qnKlSvndFnIImPGjNHkyZN1+PDhnC4FGVSrVi3VqFFDEyZMkCSlpKTI29tbffv21ZAhQ3K4OtyvM2fOyMPDQ+vXr1eDBg1yuhzchwsXLqhq1aqaNGmS3n//fVWuXFnjxo3L6bJwD4YMGaKNGzfqt99+y+lSkEms+GWDqKgoRUdHy87OTlWqVJGXl5eaN2+u3bt353RpuA+nT59Wt27d9M0338jZ2Tmny0E2SEhIUJEiRXK6DGTQtWvX9Mcff6hJkybWNjs7OzVp0kSbN2/OwcqQVRISEiSJ35cm0Lt3bz3zzDM2v1+RO/3www+qXr262rRpIw8PD1WpUkVffvllTpeFDCD4ZYPU1YKwsDC98847+vHHH1W4cGEFBQUpLi4uh6vDvTAMQ6GhoerRo4eqV6+e0+UgGxw6dEjjx4/X66+/ntOlIINiY2OVnJysYsWK2bQXK1ZMp06dyqGqkFVSUlLUv39/1a1bV4GBgTldDu7Dd999p6ioKEVEROR0KcgChw8f1uTJk1WmTBn9/PPP6tmzp/r166cZM2bkdGm4C4JfJgwZMkQWi+WOP6n3DUnS22+/rRdffFHVqlVTZGSkLBaL5s2bl8NngZtldE7Hjx+v8+fPa+jQoTldMu4io3N6s+joaDVr1kxt2rRRt27dcqhyADfr3bu3du/ere+++y6nS8F9+Pfff/XGG29o9uzZcnR0zOlykAVSUlJUtWpVjRo1SlWqVFH37t3VrVs3ffHFFzldGu4iT04XkJsMHDhQoaGhd+zj5+enkydPSpICAgKs7Q4ODvLz89Px48ezs0RkUkbn9JdfftHmzZvl4OBgs6969erq0KEDf8v1EMnonKY6ceKEGjVqpDp16mjq1KnZXB2yUtGiRWVvb6/Tp0/btJ8+fVqenp45VBWyQp8+ffTjjz/q119/1WOPPZbT5eA+/PHHH4qJiVHVqlWtbcnJyfr11181YcIEXb16Vfb29jlYITLLy8vL5s+4klS+fHktWLAghypCRhH8MsHd3V3u7u537VetWjU5ODho//79qlevniQpKSlJR48eValSpbK7TGRCRuf0888/1/vvv2/dPnHihIKDgzV37lzVqlUrO0tEJmV0TqUbK32NGjWyrsrb2XERRG6SL18+VatWTWvWrLG+LiclJUVr1qxRnz59crY43BPDMNS3b18tWrRI69atk6+vb06XhPvUuHFj7dq1y6atS5cuKleunAYPHkzoy4Xq1q2b5jUrBw4c4M+4uQDBLxu4uLioR48eGjlypLy9vVWqVCmNGTNGktSmTZscrg73omTJkjbbBQoUkCT5+/vzt9G5VHR0tIKCglSqVCmNHTtWZ86cse5jtSj3GDBggDp37qzq1aurZs2aGjdunC5evKguXbrkdGm4B71799acOXO0ZMkSFSxY0Hqvpqurq5ycnHK4OtyLggULprlHM3/+/HJzc+PezVzqzTffVJ06dTRq1CiFhIRo69atmjp1KlfN5AIEv2wyZswY5cmTR6+88oouX76sWrVq6ZdffuEdJ8BDYtWqVTp06JAOHTqUJrzzlpvco23btjpz5oxGjBihU6dOqXLlylqxYkWaB74gd5g8ebIkKSgoyKY9MjLyrpdwA3gwatSooUWLFmno0KF699135evrq3HjxqlDhw45XRrugvf4AQAAAIDJcUMLAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJMj+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AHmGhoaGyWCyyWCzKly+fSpcurXfffVfXr1+39jEMQ1OnTlWtWrVUoEABFSpUSNWrV9e4ceN06dIlm/H+++8/5cuXT4GBgRmu4dSpU+rbt6/8/Pzk4OAgb29vtWzZUmvWrMmy8zSD0NBQtW7d+q79fv31V7Vs2VLFixeXxWLR4sWLs702AMDDj+AHAI+4Zs2a6eTJkzp48KAGDhyosLAwjRkzxrr/lVdeUf/+/fXcc89p7dq12rFjh4YPH64lS5Zo5cqVNmNNnz5dISEhSkxM1O+//37XYx89elTVqlXTL7/8ojFjxmjXrl1asWKFGjVqpN69e2f5uT4KLl68qEqVKmnixIk5XQoA4GFiAAAeWZ07dzaee+45m7amTZsaTz75pGEYhjF37lxDkrF48eI0n01JSTHi4+Nttv38/IwVK1YYgwcPNrp163bX4zdv3twoUaKEceHChTT7zp07Z/33Y8eOGa1atTLy589vFCxY0GjTpo1x6tQp6/6RI0calSpVMqZNm2Z4e3sb+fPnN3r27Glcv37dGD16tFGsWDHD3d3deP/9922OIcmYNGmS0axZM8PR0dHw9fU15s2bZ9Pnr7/+Mho1amQ4OjoaRYoUMbp162acP38+zXc4ZswYw9PT0yhSpIjRq1cv49q1a9Y+V65cMQYOHGgUL17ccHZ2NmrWrGmsXbvWuj8yMtJwdXU1VqxYYZQrV87Inz+/ERwcbJw4ccJ6fpJsfm7+/O1IMhYtWnTXfgAA82PFDwBgw8nJSdeuXZMkzZ49W2XLltVzzz2Xpp/FYpGrq6t1e+3atbp06ZKaNGmijh076rvvvtPFixdve5y4uDitWLFCvXv3Vv78+dPsL1SokCQpJSVFzz33nOLi4rR+/XqtWrVKhw8fVtu2bW36//PPP1q+fLlWrFihb7/9VtOmTdMzzzyj//77T+vXr9fo0aP1zjvvpFmJHD58uF588UXt3LlTHTp0ULt27bR3715JN1bPgoODVbhwYW3btk3z5s3T6tWr1adPH5sx1q5dq3/++Udr167VjBkzNH36dE2fPt26v0+fPtq8ebO+++47/fXXX2rTpo2aNWumgwcPWvtcunRJY8eO1TfffKNff/1Vx48f16BBgyRJgwYNUkhIiHV19uTJk6pTp85tv1sAANLI6eQJAMg5N6/4paSkGKtWrTIcHByMQYMGGYZhGOXLlzdatWqVobHat29v9O/f37pdqVIlIzIy8rb9f//9d0OSsXDhwjuOu3LlSsPe3t44fvy4te3vv/82JBlbt241DOPGipizs7ORmJho7RMcHGz4+PgYycnJ1rayZcsaERER1m1JRo8ePWyOV6tWLaNnz56GYRjG1KlTjcKFC9usSP7000+GnZ2ddcWxc+fORqlSpYzr169b+7Rp08Zo27atYRg3Vivt7e2N6Ohom+M0btzYGDp0qGEYN1b8JBmHDh2y7p84caJRrFgx63Z6q7N3I1b8AAD/J0+Opk4AQI778ccfVaBAASUlJSklJUXt27dXWFiYpBsPdsmI+Ph4LVy4UBs2bLC2dezYUdOmTVNoaGi6n8no2Hv37pW3t7e8vb2tbQEBASpUqJD27t2rGjVqSJJ8fHxUsGBBa59ixYrJ3t5ednZ2Nm0xMTE249euXTvN9o4dO6zHrlSpks2KZN26dZWSkqL9+/erWLFikqQKFSrI3t7e2sfLy0u7du2SJO3atUvJycl6/PHHbY5z9epVubm5WbednZ3l7+9vM8attQIAcK8IfgDwiGvUqJEmT56sfPnyqXjx4sqT5///r+Hxxx/Xvn377jrGnDlzdOXKFdWqVcvaZhiGUlJSdODAgTShR5LKlCkji8WSofEzIm/evDbbFosl3baUlJQsOd7djp16nAsXLsje3l5//PGHTTiUpAIFCtxxjIyGYwAA7oZ7/ADgEZc/f36VLl1aJUuWtAl9ktS+fXsdOHBAS5YsSfM5wzCUkJAgSZo2bZoGDhyoHTt2WH927typ+vXr6+uvv073uEWKFFFwcLAmTpyY7r2A8fHxkqTy5cvr33//1b///mvdt2fPHsXHxysgIOBeT9tqy5YtabbLly9vPfbOnTtt6tu4caPs7OxUtmzZDI1fpUoVJScnKyYmRqVLl7b58fT0zHCd+fLlU3Jycob7AwBwM4IfAOC2QkJC1LZtW7388ssaNWqUtm/frmPHjunHH39UkyZNrK93iIqKUteuXRUYGGjz8/LLL2vGjBk27wW82cSJE5WcnKyaNWtqwYIFOnjwoPbu3avPP//ceglmkyZNVLFiRXXo0EFRUVHaunWrOnXqpIYNG6p69er3fY7z5s3T119/rQMHDmjkyJHaunWr9eEtHTp0kKOjozp37qzdu3dr7dq16tu3r1555RXrZZ538/jjj6tDhw7q1KmTFi5cqCNHjmjr1q2KiIjQTz/9lOE6fXx89Ndff2n//v2KjY1VUlJSuv0uXLhgDd+SdOTIEe3YsUPHjx/P8LEAAOZD8AMA3JbFYtGcOXP0ySefaPHixWrYsKGeeOIJhYWF6bnnnlNwcLCmTZumgIAAlStXLs3nn3/+ecXExGjZsmXpju/n56eoqCg1atRIAwcOVGBgoJo2bao1a9Zo8uTJ1hqWLFmiwoULq0GDBmrSpIn8/Pw0d+7cLDnH8PBwfffdd3riiSc0c+ZMffvtt9aVRGdnZ/3888+Ki4tTjRo19NJLL6lx48aaMGFCpo4RGRmpTp06aeDAgSpbtqxat26tbdu2qWTJkhkeo1u3bipbtqyqV68ud3d3bdy4Md1+27dvV5UqVVSlShVJ0oABA1SlShWNGDEiUzUDAMzFYnADAQDgEWWxWLRo0SK1bt06p0sBACBbseIHAAAAACZH8AMAAAAAk+N1DgCARxZ3OwAAHhWs+AEAAACAyRH8AAAAAMDkCH4AAAAAYHIEPwAAAAAwOYIfAAAAAJgcwQ8AAAAATI7gBwAAAAAmR/ADAAAAAJP7f5JVOBjOCa0yAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Function to get embeddings for multiple words\n",
    "def get_word_embeddings(words, vocab, model):\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in reverse_vocab:\n",
    "            index = reverse_vocab[word]\n",
    "            embedding = model.emb(torch.LongTensor([index]).to(device)).detach().cpu().numpy()\n",
    "            embeddings.append(embedding[0])  # Get the first (and only) element of the array\n",
    "        else:\n",
    "            print(f\"'{word}' not found in the vocabulary.\")\n",
    "            embeddings.append(None)  # Placeholder for unknown words\n",
    "    return embeddings\n",
    "\n",
    "# Words to visualize\n",
    "words_to_visualize = [\"house\", \"home\", \"plane\", \"car\", \"nba\", \"nfl\",\"football\",\"vehicle\",\"abode\",\"basketball\",\n",
    "                      \"biden\"]  # Replace with your words\n",
    "\n",
    "# Get embeddings for the selected words\n",
    "embeddings = get_word_embeddings(words_to_visualize, updated_vocab, mFoo)\n",
    "\n",
    "# Remove None values from embeddings\n",
    "embeddings = [emb for emb in embeddings if emb is not None]\n",
    "\n",
    "# Step 2: Reduce dimensionality using PCA or t-SNE\n",
    "# Here, we're using PCA for simplicity, but you can also use t-SNE for better visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Step 3: Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "# Annotate points with corresponding words\n",
    "for i, word in enumerate(words_to_visualize):\n",
    "    if embeddings[i] is not None:\n",
    "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]), fontsize=12)\n",
    "\n",
    "plt.title('Word Embeddings Visualization')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running model based on loaded in embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231284, 64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title_cleaned</th>\n",
       "      <th>domain</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375051</td>\n",
       "      <td>a culture where change is ordinary</td>\n",
       "      <td>katalisha.com</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://katalisha.com/devops/2021/08/26/idealc...</td>\n",
       "      <td>2022-01-25 02:24:12</td>\n",
       "      <td>2</td>\n",
       "      <td>30067098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375052</td>\n",
       "      <td>what americans lost when we abandoned the secr...</td>\n",
       "      <td>www.galioninquirer.com</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.galioninquirer.com/opinion/72009/w...</td>\n",
       "      <td>2022-01-25 02:24:28</td>\n",
       "      <td>23</td>\n",
       "      <td>30067100</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375053</td>\n",
       "      <td>extinct languages</td>\n",
       "      <td>en.wikipedia.org</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Extinct_language</td>\n",
       "      <td>2022-02-21 16:09:58</td>\n",
       "      <td>1</td>\n",
       "      <td>30417385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375054</td>\n",
       "      <td>our outdated marijuana laws put americans in d...</td>\n",
       "      <td>www.usatoday.com</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://www.usatoday.com/story/opinion/2022/02...</td>\n",
       "      <td>2022-02-21 16:11:06</td>\n",
       "      <td>3</td>\n",
       "      <td>30417395</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375056</td>\n",
       "      <td>the seven rules of the metaverse</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://medium.com/meta-verses/the-seven-rules...</td>\n",
       "      <td>2021-10-25 22:02:49</td>\n",
       "      <td>2</td>\n",
       "      <td>28993098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231279</th>\n",
       "      <td>1875240</td>\n",
       "      <td>why i moved my startup to oakland</td>\n",
       "      <td>brennenbyrne.com</td>\n",
       "      <td>2013</td>\n",
       "      <td>http://brennenbyrne.com/2013/09/oakland/</td>\n",
       "      <td>2013-09-24 23:55:56</td>\n",
       "      <td>67</td>\n",
       "      <td>6441376</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231280</th>\n",
       "      <td>1875242</td>\n",
       "      <td>investment scam</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://medium.com/@englishpaulm/investment-sc...</td>\n",
       "      <td>2015-09-28 09:42:24</td>\n",
       "      <td>1</td>\n",
       "      <td>10289446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231281</th>\n",
       "      <td>1875244</td>\n",
       "      <td>comparison between quill and other cassandra l...</td>\n",
       "      <td>github.com</td>\n",
       "      <td>2016</td>\n",
       "      <td>https://github.com/getquill/quill/blob/master/...</td>\n",
       "      <td>2016-02-19 20:13:01</td>\n",
       "      <td>1</td>\n",
       "      <td>11136262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231282</th>\n",
       "      <td>1875245</td>\n",
       "      <td>get you ember fest ticket</td>\n",
       "      <td>emberfest.eu</td>\n",
       "      <td>2014</td>\n",
       "      <td>http://emberfest.eu/tickets</td>\n",
       "      <td>2014-04-24 07:19:05</td>\n",
       "      <td>1</td>\n",
       "      <td>7638755</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231283</th>\n",
       "      <td>1875246</td>\n",
       "      <td>night walk in marseille</td>\n",
       "      <td>nightwalk.withgoogle.com</td>\n",
       "      <td>2014</td>\n",
       "      <td>https://nightwalk.withgoogle.com/en/</td>\n",
       "      <td>2014-04-24 07:20:12</td>\n",
       "      <td>1</td>\n",
       "      <td>7638758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1231284 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                      title_cleaned  \\\n",
       "0            375051                 a culture where change is ordinary   \n",
       "1            375052  what americans lost when we abandoned the secr...   \n",
       "2            375053                                  extinct languages   \n",
       "3            375054  our outdated marijuana laws put americans in d...   \n",
       "4            375056                   the seven rules of the metaverse   \n",
       "...             ...                                                ...   \n",
       "1231279     1875240                  why i moved my startup to oakland   \n",
       "1231280     1875242                                    investment scam   \n",
       "1231281     1875244  comparison between quill and other cassandra l...   \n",
       "1231282     1875245                          get you ember fest ticket   \n",
       "1231283     1875246                            night walk in marseille   \n",
       "\n",
       "                           domain  year  \\\n",
       "0                   katalisha.com  2022   \n",
       "1          www.galioninquirer.com  2022   \n",
       "2                en.wikipedia.org  2022   \n",
       "3                www.usatoday.com  2022   \n",
       "4                      medium.com  2021   \n",
       "...                           ...   ...   \n",
       "1231279          brennenbyrne.com  2013   \n",
       "1231280                medium.com  2015   \n",
       "1231281                github.com  2016   \n",
       "1231282              emberfest.eu  2014   \n",
       "1231283  nightwalk.withgoogle.com  2014   \n",
       "\n",
       "                                                       url  \\\n",
       "0        https://katalisha.com/devops/2021/08/26/idealc...   \n",
       "1        https://www.galioninquirer.com/opinion/72009/w...   \n",
       "2           https://en.wikipedia.org/wiki/Extinct_language   \n",
       "3        https://www.usatoday.com/story/opinion/2022/02...   \n",
       "4        https://medium.com/meta-verses/the-seven-rules...   \n",
       "...                                                    ...   \n",
       "1231279           http://brennenbyrne.com/2013/09/oakland/   \n",
       "1231280  https://medium.com/@englishpaulm/investment-sc...   \n",
       "1231281  https://github.com/getquill/quill/blob/master/...   \n",
       "1231282                        http://emberfest.eu/tickets   \n",
       "1231283               https://nightwalk.withgoogle.com/en/   \n",
       "\n",
       "                        time  score        id  descendants  \n",
       "0        2022-01-25 02:24:12      2  30067098          0.0  \n",
       "1        2022-01-25 02:24:28     23  30067100         54.0  \n",
       "2        2022-02-21 16:09:58      1  30417385          0.0  \n",
       "3        2022-02-21 16:11:06      3  30417395          0.0  \n",
       "4        2021-10-25 22:02:49      2  28993098          0.0  \n",
       "...                      ...    ...       ...          ...  \n",
       "1231279  2013-09-24 23:55:56     67   6441376         60.0  \n",
       "1231280  2015-09-28 09:42:24      1  10289446          0.0  \n",
       "1231281  2016-02-19 20:13:01      1  11136262          0.0  \n",
       "1231282  2014-04-24 07:19:05      1   7638755          0.0  \n",
       "1231283  2014-04-24 07:20:12      1   7638758          0.0  \n",
       "\n",
       "[1231284 rows x 9 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = valid_titles_df['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Task_Dataset(Dataset):\n",
    "    def __init__(self, embeddings_df: pd.DataFrame, y: np.ndarray):\n",
    "        # Convert embeddings_df to tensor\n",
    "        self.X = torch.tensor(embeddings_df.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y).float()  # Target labels, converted to tensor\n",
    "        assert self.X.shape[0] == self.y.shape[0], \"Embeddings and targets must have the same number of samples\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]  # Return the number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Return the embedding and the corresponding target\n",
    "\n",
    "y_train = valid_titles_df['score'].to_numpy()\n",
    "# Create dataset\n",
    "task_ds = Task_Dataset(embeddings_df, y_train)\n",
    "\n",
    "# Create dataloader\n",
    "task_dl = DataLoader(task_ds, batch_size=512, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SingleTask_Network(nn.Module):\n",
    "    def __init__(self, input_dim: int = 64, hidden_dim_1: int = 300, hidden_dim_2: int = 200, hidden_dim_3: int = 150, hidden_dim_4: int = 100, hidden_dim_5: int = 50, output_dim: int = 1):\n",
    "        super(SingleTask_Network, self).__init__()\n",
    "        \n",
    "        # First hidden layer\n",
    "        self.hidden_1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        # Second hidden layer\n",
    "        self.hidden_2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        # Third hidden layer\n",
    "        self.hidden_3 = nn.Linear(hidden_dim_2, hidden_dim_3)\n",
    "        # Fourth hidden layer\n",
    "        self.hidden_4 = nn.Linear(hidden_dim_3, hidden_dim_4)\n",
    "        # Fifth hidden layer\n",
    "        self.hidden_5 = nn.Linear(hidden_dim_4, hidden_dim_5)\n",
    "        # Final output layer\n",
    "        self.final = nn.Linear(hidden_dim_5, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Pass through each hidden layer with ReLU activation\n",
    "        x = torch.relu(self.hidden_1(x))\n",
    "        x = torch.relu(self.hidden_2(x))\n",
    "        x = torch.relu(self.hidden_3(x))\n",
    "        x = torch.relu(self.hidden_4(x))\n",
    "        x = torch.relu(self.hidden_5(x))\n",
    "        # Final output layer (no activation for regression)\n",
    "        x = self.final(x)\n",
    "        return x.squeeze() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize the model\n",
    "model = SingleTask_Network(input_dim=task_ds.X.shape[1], output_dim=1)  # Using task_ds.X for input dimension\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Loss function: Use MSELoss for regression\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0rnekxey) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Batch Loss</td><td>▄▂▃▃▂▁▂▂▂▂▃▂▂▃▁▃▂▂▂▅▁▃█▂▆▂▇▄█▄▂▄▅▁▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Batch Loss</td><td>4698.14795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">batch_size(512)</strong> at: <a href='https://wandb.ai/omareweis123/singletask_training/runs/0rnekxey' target=\"_blank\">https://wandb.ai/omareweis123/singletask_training/runs/0rnekxey</a><br/> View project at: <a href='https://wandb.ai/omareweis123/singletask_training' target=\"_blank\">https://wandb.ai/omareweis123/singletask_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_151736-0rnekxey\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0rnekxey). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"singletask_training\", entity=\"omareweis123\", name='batch_size(512)') # Replace with your project and entity names\n",
    "\n",
    "# Number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0  # To calculate average loss for the epoch\n",
    "\n",
    "    # Create a tqdm progress bar for the entire epoch\n",
    "    with tqdm(total=len(task_dl), desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False) as pbar:\n",
    "        for j, (batch_X, batch_y) in enumerate(task_dl):\n",
    "            # Forward pass\n",
    "            preds = model(batch_X)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn(preds, batch_y)\n",
    "            epoch_loss += loss.item()  # Accumulate loss\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar with the current loss\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)  # Increment the progress bar\n",
    "            \n",
    "            # Log the batch loss to W&B\n",
    "            wandb.log({'Batch Loss': loss.item()})\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = epoch_loss / len(task_dl)\n",
    "    \n",
    "    # Log average loss for the epoch to W&B\n",
    "    wandb.log({'Average Epoch Loss': avg_loss})\n",
    "\n",
    "    # Optional: Print the final loss for the epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Final Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Finish W&B logging\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to regression_20epochs_titles.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model after training\n",
    "model_save_path = \"regression_20epochs_titles.pth\"  # You can name the file as you like\n",
    "torch.save(mFoo.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([50, 64]), Targets shape: torch.Size([50])\n",
      "Predictions shape: torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in task_dl:\n",
    "    movie_batch_X, movie_batch_y = batch\n",
    "    print(f\"Batch shape: {movie_batch_X.shape}, Targets shape: {movie_batch_y.shape}\")\n",
    "\n",
    "    # Forward pass\n",
    "    movie_preds = model(movie_batch_X)\n",
    "    print(f\"Predictions shape: {movie_preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuring multitask model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Task_Dataset(Dataset):\n",
    "    def __init__(self, embeddings_df: pd.DataFrame, y: np.ndarray):\n",
    "        # Convert embeddings_df to tensor\n",
    "        self.X = torch.tensor(embeddings_df.values).float()  # Convert DataFrame to tensor\n",
    "        self.y = torch.from_numpy(y).float()  # Target labels, converted to tensor\n",
    "        assert self.X.shape[0] == self.y.shape[0], \"Embeddings and targets must have the same number of samples\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]  # Return the number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Return the embedding and the corresponding target\n",
    "\n",
    "y_train = np.random.randint(1, 501, size=embeddings_df.shape[0])\n",
    "# Create dataset\n",
    "task_ds = Task_Dataset(embeddings_df, y_train)\n",
    "\n",
    "# Create dataloader\n",
    "task_dl = DataLoader(task_ds, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year\n",
      "0  2000\n",
      "1  2019\n",
      "2  2013\n",
      "3  2009\n",
      "4  2020\n",
      "[137 439 366 289  39]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming the number of samples is the same as in task_ds\n",
    "num_samples = embeddings_df.shape[0]\n",
    "\n",
    "# Generate random years, for example between 2000 and 2023\n",
    "random_years = np.random.randint(2000, 2024, size=num_samples)\n",
    "\n",
    "# Convert the random years to a DataFrame\n",
    "yelp_X_train = pd.DataFrame(random_years, columns=['Year'])\n",
    "\n",
    "# Use the same y_train from the previous dataset\n",
    "yelp_y_train = y_train  # y_train remains the same as in task_ds\n",
    "\n",
    "# Create the new dataset for multi-task learning\n",
    "yelp_ds = Task_Dataset(yelp_X_train, yelp_y_train)\n",
    "\n",
    "# Create the DataLoader for the new dataset\n",
    "yelp_dl = DataLoader(yelp_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# Optional: Check the first few entries in the new dataset\n",
    "print(yelp_X_train.head())\n",
    "print(yelp_y_train[:5])  # Display first 5 entries of y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiTask_Network(nn.Module):\n",
    "    def __init__(self, input_dim, \n",
    "                 output_dim_0: int = 1, output_dim_1: int = 1,  # Assuming output_dim_1 is for scores\n",
    "                 hidden_dim: int = 200):\n",
    "        \n",
    "        super(MultiTask_Network, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim_0 = output_dim_0\n",
    "        self.output_dim_1 = output_dim_1\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.hidden = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.final_0 = nn.Linear(self.hidden_dim, self.output_dim_0)  # For the regression task\n",
    "        self.final_1 = nn.Linear(self.hidden_dim, self.output_dim_1)  # For the years to scores task     \n",
    "\n",
    "    def forward(self, x: torch.Tensor, task_id: int):\n",
    "        x = self.hidden(x)\n",
    "        \n",
    "        # Use ReLU or no activation (linear) for regression\n",
    "        x = torch.relu(x)  # You can also choose to leave it linear (no activation)\n",
    "        \n",
    "        if task_id == 0:  # For task_ds\n",
    "            x = self.final_0(x)  # Linear output for regression\n",
    "        elif task_id == 1:  # For the years to scores task\n",
    "            x = self.final_1(x)  # Linear output or another suitable activation\n",
    "        else:\n",
    "            assert False, 'Bad Task ID passed'\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MultiTask_Network model\n",
    "model = MultiTask_Network(input_dim=embeddings_df.shape[1],  # or movie_ds.X.shape[1]\n",
    "                           output_dim_0=1,  # Single output for the regression task (task_ds)\n",
    "                           output_dim_1=1)  # Single output for the scores task (yelp)\n",
    "\n",
    "# Choose an optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Use Mean Squared Error for both regression tasks\n",
    "movie_loss_fn = nn.MSELoss()  # For task_ds regression\n",
    "yelp_loss_fn = nn.MSELoss()    # For yelp scores regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x1 and 64x200)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m yelp_batch_X \u001b[38;5;241m=\u001b[39m yelp_batch_X\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape if necessary\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Forward pass for yelp task\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m yelp_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43myelp_batch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m yelp_loss \u001b[38;5;241m=\u001b[39m yelp_loss_fn(yelp_preds, yelp_batch_y)  \u001b[38;5;66;03m# Ensure yelp_batch_y is the correct target\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Combined loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omare\\anaconda3\\envs\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\omare\\anaconda3\\envs\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 20\u001b[0m, in \u001b[0;36mMultiTask_Network.forward\u001b[1;34m(self, x, task_id)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, task_id: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Use ReLU or no activation (linear) for regression\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)  \u001b[38;5;66;03m# You can also choose to leave it linear (no activation)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omare\\anaconda3\\envs\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\omare\\anaconda3\\envs\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omare\\anaconda3\\envs\\.conda\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x1 and 64x200)"
     ]
    }
   ],
   "source": [
    "# Number of epochs for training\n",
    "num_epochs = 6\n",
    "losses_per_epoch = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0  # To track loss per epoch\n",
    "\n",
    "    # Assuming task_dl returns both movie and yelp data\n",
    "    for j, ((movie_batch_X, movie_batch_y), (yelp_batch_X, yelp_batch_y)) in enumerate(zip(task_dl, yelp_dl)):\n",
    "        # Forward pass for movie task\n",
    "        movie_preds = model(movie_batch_X, task_id=0)\n",
    "        movie_loss = movie_loss_fn(movie_preds, movie_batch_y)\n",
    "\n",
    "        # Ensure yelp input is correctly shaped\n",
    "        yelp_batch_X = yelp_batch_X.float().view(-1, 1)  # Reshape if necessary\n",
    "        \n",
    "        # Forward pass for yelp task\n",
    "        yelp_preds = model(yelp_batch_X, task_id=1)\n",
    "        yelp_loss = yelp_loss_fn(yelp_preds, yelp_batch_y)  # Ensure yelp_batch_y is the correct target\n",
    "\n",
    "        # Combined loss\n",
    "        loss = movie_loss + yelp_loss\n",
    "        epoch_loss += loss.item()  # Accumulate epoch loss\n",
    "        losses_per_epoch.append(loss.item())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Optional: Print loss every few batches for monitoring\n",
    "        if j % 100 == 0:  # Adjust this value as needed for how frequently you want to print\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{j + 1}/{len(task_dl)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Log average loss for the epoch (optional)\n",
    "    avg_loss = epoch_loss / len(task_dl)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of builtin_function_or_method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m yelp_X_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(yelp_X_train\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Create the new dataset for multi-task learning\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m yelp_ds \u001b[38;5;241m=\u001b[39m \u001b[43mTask_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43myelp_X_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myelp_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Create DataLoader for the Yelp dataset\u001b[39;00m\n\u001b[0;32m     41\u001b[0m yelp_dl \u001b[38;5;241m=\u001b[39m DataLoader(yelp_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[46], line 11\u001b[0m, in \u001b[0;36mTask_Dataset.__init__\u001b[1;34m(self, embeddings_df, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, embeddings_df: pd\u001b[38;5;241m.\u001b[39mDataFrame, y: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Convert DataFrame to tensor\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Target labels, converted to tensor\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings and targets must have the same number of samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of builtin_function_or_method"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
