Epoch 1/50:   0%|          | 0/1 [00:00<?, ?it/s]c:\Users\omare\anaconda3\envs\.conda\Lib\site-packages\torch\nn\modules\loss.py:538: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
                                                            
Epoch [1/50], Final Loss: 720.5283
Epoch [2/50], Final Loss: 720.3190
Epoch [3/50], Final Loss: 720.0956
Epoch [4/50], Final Loss: 719.8718
Epoch [5/50], Final Loss: 719.6581
Epoch [6/50], Final Loss: 719.4633
Epoch [7/50], Final Loss: 719.2923
Epoch [8/50], Final Loss: 719.1486
Epoch [9/50], Final Loss: 719.0333
Epoch [10/50], Final Loss: 718.9448
Epoch [11/50], Final Loss: 718.8815
Epoch [12/50], Final Loss: 718.8404
Epoch [13/50], Final Loss: 718.8179
Epoch [14/50], Final Loss: 718.8099
Epoch [15/50], Final Loss: 718.8135
Epoch [16/50], Final Loss: 718.8250
Epoch [17/50], Final Loss: 718.8414
Epoch [18/50], Final Loss: 718.8600
Epoch [19/50], Final Loss: 718.8787
Epoch [20/50], Final Loss: 718.8960
Epoch [21/50], Final Loss: 718.9108
Epoch [22/50], Final Loss: 718.9221
Epoch [23/50], Final Loss: 718.9297
Epoch [24/50], Final Loss: 718.9334
Epoch [25/50], Final Loss: 718.9333
Epoch [26/50], Final Loss: 718.9302
Epoch [27/50], Final Loss: 718.9237
Epoch [28/50], Final Loss: 718.9151
Epoch [29/50], Final Loss: 718.9049
Epoch [30/50], Final Loss: 718.8934
Epoch [31/50], Final Loss: 718.8815
Epoch [32/50], Final Loss: 718.8698
Epoch [33/50], Final Loss: 718.8583
Epoch [34/50], Final Loss: 718.8478
Epoch [35/50], Final Loss: 718.8384
Epoch [36/50], Final Loss: 718.8303
Epoch [37/50], Final Loss: 718.8237
Epoch [38/50], Final Loss: 718.8184
Epoch [39/50], Final Loss: 718.8146
Epoch [40/50], Final Loss: 718.8121
Epoch [41/50], Final Loss: 718.8107
Epoch [42/50], Final Loss: 718.8100
Epoch [43/50], Final Loss: 718.8102
Epoch [44/50], Final Loss: 718.8109
Epoch [45/50], Final Loss: 718.8118
Epoch [46/50], Final Loss: 718.8130
Epoch [47/50], Final Loss: 718.8142
Epoch [48/50], Final Loss: 718.8152
Epoch [49/50], Final Loss: 718.8161
Epoch [50/50], Final Loss: 718.8168
